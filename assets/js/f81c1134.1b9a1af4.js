"use strict";(self.webpackChunkbri_b_dev_github_io=self.webpackChunkbri_b_dev_github_io||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"field-filtering-rest-jackson","metadata":{"permalink":"/blog/field-filtering-rest-jackson","source":"@site/blog/2025-02-17-field-filtering.md","title":"Field-Filtering in REST-APIs mit Jackson & @ControllerAdvice","description":"Dynamische Reduktion von Response-Feldern \xfcber Query-Parameter \u2013 elegante L\xf6sung mit Mixins und MappingJacksonValue.","date":"2025-02-17T00:00:00.000Z","tags":[{"inline":false,"label":"Spring Boot","permalink":"/blog/tags/spring-boot","description":"Spring Boot"},{"inline":false,"label":"Kotlin","permalink":"/blog/tags/kotlin","description":"Kotlin"},{"inline":false,"label":"Java","permalink":"/blog/tags/java","description":"Java"},{"inline":false,"label":"REST","permalink":"/blog/tags/rest","description":"REST"},{"inline":false,"label":"Jackson","permalink":"/blog/tags/jackson","description":"Jackson"},{"inline":false,"label":"Json","permalink":"/blog/tags/json","description":"JavaScript Object Notation"}],"readingTime":1.79,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"field-filtering-rest-jackson","title":"Field-Filtering in REST-APIs mit Jackson & @ControllerAdvice","authors":"brigitte","tags":["spring-boot","kotlin","java","rest","jackson","json"],"date":"2025-02-17T00:00:00.000Z","description":"Dynamische Reduktion von Response-Feldern \xfcber Query-Parameter \u2013 elegante L\xf6sung mit Mixins und MappingJacksonValue."},"unlisted":false,"nextItem":{"title":"API-First mit Spring Boot & Kotlin","permalink":"/blog/api-first-springboot-kotlin"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nOft wollen Clients **nicht alle Felder** einer REST-Response zur\xfcckbekommen.  \\nBeispiele:\\n- Mobile Apps brauchen nur `id` und `name`, nicht das komplette DTO.  \\n- Analytics-Systeme wollen nur bestimmte Metriken.  \\n\x3c!--truncate--\x3e\\nStatt mehrere Endpunkte zu bauen, kann man **Field-Filtering per Query-Parameter** implementieren:  \\n`GET /api/spaces?fields=id,name`\\n\\n---\\n\\n## \u2699\ufe0f Setup\\nWir nutzen:\\n- **Spring Boot (Kotlin/Java)**  \\n- **Jackson @JsonFilter + Mixins**  \\n- **@ControllerAdvice**, das `MappingJacksonValue` zur\xfcckgibt  \\n\\n---\\n\\n## \ud83d\udd17 Beispiel: DTOs & Controller\\n\\n**`SpaceReadDTO.kt`**\\n```kotlin\\ndata class SpaceReadDTO(\\n    val id: UUID,\\n    val name: String,\\n    val description: String,\\n    val createdAt: Instant,\\n    val owner: String\\n)\\n````\\n\\n**`SpaceController.kt`**\\n\\n```kotlin\\n@RestController\\n@RequestMapping(\\"/api/spaces\\")\\nclass SpaceController {\\n\\n    @GetMapping\\n    fun getSpaces(): List<SpaceReadDTO> =\\n        listOf(\\n            SpaceReadDTO(UUID.randomUUID(), \\"Alpha\\", \\"First Space\\", Instant.now(), \\"Brigitte\\"),\\n            SpaceReadDTO(UUID.randomUUID(), \\"Beta\\", \\"Second Space\\", Instant.now(), \\"Alex\\")\\n        )\\n}\\n```\\n\\n\ud83d\udc49 Noch ohne Filterung.\\n\\n---\\n\\n## \ud83e\ude84 Field-Filter Advice\\n\\nWir schreiben ein **@ControllerAdvice**, das Responses abf\xe4ngt und bei Bedarf Felder reduziert:\\n\\n**`FieldFilterAdvice.kt`**\\n\\n```kotlin\\n@ControllerAdvice\\nclass FieldFilterAdvice(val objectMapper: ObjectMapper) : ResponseBodyAdvice<Any> {\\n\\n    override fun supports(\\n        returnType: MethodParameter,\\n        converterType: Class<out HttpMessageConverter<*>>\\n    ) = true\\n\\n    override fun beforeBodyWrite(\\n        body: Any?,\\n        returnType: MethodParameter,\\n        contentType: MediaType,\\n        converterType: Class<out HttpMessageConverter<*>>,\\n        request: ServerHttpRequest,\\n        response: ServerHttpResponse\\n    ): Any? {\\n        if (body == null) return null\\n\\n        val servletRequest = (request as? ServletServerHttpRequest)?.servletRequest\\n        val fieldsParam = servletRequest?.getParameter(\\"fields\\") ?: return body\\n\\n        val fields = fieldsParam.split(\\",\\").map { it.trim() }.toSet()\\n        if (fields.isEmpty()) return body\\n\\n        // Dynamisches Filter-Setup\\n        val filterId = \\"dynamicFilter\\"\\n        objectMapper.setFilterProvider(\\n            SimpleFilterProvider().addFilter(\\n                filterId,\\n                SimpleBeanPropertyFilter.filterOutAllExcept(fields)\\n            )\\n        )\\n\\n        // Mixin mit @JsonFilter\\n        val targetClass = body.javaClass\\n        objectMapper.addMixIn(targetClass, DynamicFilterMixin::class.java)\\n\\n        return MappingJacksonValue(body).apply { filters = objectMapper.serializationConfig.filterProvider }\\n    }\\n\\n    @JsonFilter(\\"dynamicFilter\\")\\n    class DynamicFilterMixin\\n}\\n```\\n\\n---\\n\\n## \ud83d\ude80 Ergebnis\\n\\nAufruf ohne Parameter:\\n\\n```http\\nGET /api/spaces\\n```\\n\\nResponse:\\n\\n```json\\n[\\n  { \\"id\\": \\"\u2026\\", \\"name\\": \\"Alpha\\", \\"description\\": \\"First Space\\", \\"createdAt\\": \\"\u2026\\", \\"owner\\": \\"Brigitte\\" }\\n]\\n```\\n\\nAufruf mit Filter:\\n\\n```http\\nGET /api/spaces?fields=id,name\\n```\\n\\nResponse:\\n\\n```json\\n[\\n  { \\"id\\": \\"\u2026\\", \\"name\\": \\"Alpha\\" }\\n]\\n```\\n\\n---\\n\\n## \u2705 Lessons Learned\\n\\n* Funktioniert f\xfcr einzelne Objekte **und** Listen.\\n* `fields`-Parameter ist flexibel kombinierbar (`id,name,owner`).\\n* Mehrere DTOs \u2192 bei Bedarf eigene Filter-IDs und Mixins.\\n* Vorsicht bei **Nested Objects** \u2013 Field-Filtering wirkt nur auf oberster Ebene.\\n\\n<Admonition type=\\"tip\\" title=\\"Pro Tipp\\">\\nBaue dir Helper-Methoden f\xfcr h\xe4ufig genutzte Feldsets, z. B. `?fields=summary` \u2192 wird in konkrete Felder expandiert.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nMit `@ControllerAdvice`, Jackson-Filter und `MappingJacksonValue` l\xe4sst sich **Field-Filtering elegant & generisch** umsetzen.\\nDamit sparst du Boilerplate-Endpoints und gibst Clients genau die Daten zur\xfcck, die sie wirklich brauchen."},{"id":"api-first-springboot-kotlin","metadata":{"permalink":"/blog/api-first-springboot-kotlin","source":"@site/blog/2025-02-10-api-first.md","title":"API-First mit Spring Boot & Kotlin","description":"Wie ich Microservices nach OpenAPI designe und automatisch Clients & Server-Stubs generiere \u2013 Lessons Learned in Kotlin.","date":"2025-02-10T00:00:00.000Z","tags":[{"inline":false,"label":"Spring Boot","permalink":"/blog/tags/spring-boot","description":"Spring Boot"},{"inline":false,"label":"Kotlin","permalink":"/blog/tags/kotlin","description":"Kotlin"},{"inline":false,"label":"OpenAPI","permalink":"/blog/tags/openapi","description":"OpenAPI"},{"inline":false,"label":"Microservices","permalink":"/blog/tags/microservices","description":"Microservices"},{"inline":false,"label":"Codegen","permalink":"/blog/tags/codegen","description":"Codegen"},{"inline":false,"label":"API-first","permalink":"/blog/tags/api-first","description":"API-first"}],"readingTime":2.86,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"api-first-springboot-kotlin","title":"API-First mit Spring Boot & Kotlin","authors":"brigitte","tags":["spring-boot","kotlin","openapi","microservices","codegen","api-first"],"date":"2025-02-10T00:00:00.000Z","description":"Wie ich Microservices nach OpenAPI designe und automatisch Clients & Server-Stubs generiere \u2013 Lessons Learned in Kotlin."},"unlisted":false,"prevItem":{"title":"Field-Filtering in REST-APIs mit Jackson & @ControllerAdvice","permalink":"/blog/field-filtering-rest-jackson"},"nextItem":{"title":"Terraform Patterns f\xfcr AKS & Azure","permalink":"/blog/terraform-patterns-aks-azure"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nMicroservices sollen **konsistente Schnittstellen** bieten \u2013 und zwar unabh\xe4ngig von der Programmiersprache.\\nAPI-First bedeutet: **erst das OpenAPI-Schema**, dann Code, Doku & Clients.\\n\x3c!--truncate--\x3e\\nDas verhindert, dass API-Definitionen veralten oder als \u201eBeiprodukt\u201c nachgezogen werden.\\n\\n---\\n\\n## \ud83e\udde9 Workflow: API-First in der Praxis\\n\\n1. **Design**: OpenAPI-Spec (`.yaml`) mit Stoplight, Swagger Editor oder VS Code Plugin.\\n2. **Validieren**: Linter (z. B. Spectral) und CI-Checks.\\n3. **Codegen**: Server-Stubs & Client-SDKs aus der Spec generieren.\\n4. **Implementieren**: Business-Logik in Kotlin, Interface bleibt stabil.\\n5. **Docs**: Swagger UI oder ReDoc aus der gleichen Spec.\\n\\n---\\n\\n## \u2699\ufe0f Setup: OpenAPI Generator in Kotlin\\n\\n**`build.gradle.kts`**\\n\\n```kotlin\\nplugins {\\n    id(\\"org.springframework.boot\\") version \\"3.3.0\\"\\n    id(\\"io.spring.dependency-management\\") version \\"1.1.5\\"\\n    kotlin(\\"jvm\\") version \\"1.9.24\\"\\n    kotlin(\\"plugin.spring\\") version \\"1.9.24\\"\\n    id(\\"org.openapi.generator\\") version \\"7.5.0\\"\\n}\\n\\nopenApiGenerate {\\n    generatorName.set(\\"kotlin-spring\\")\\n    inputSpec.set(\\"$rootDir/api/openapi.yaml\\")\\n    outputDir.set(\\"$buildDir/generated\\")\\n    apiPackage.set(\\"com.example.api\\")\\n    modelPackage.set(\\"com.example.api.model\\")\\n    configOptions.set(\\n        mapOf(\\n            \\"interfaceOnly\\" to \\"true\\",\\n            \\"useSpringBoot3\\" to \\"true\\",\\n            \\"reactive\\" to \\"false\\"\\n        )\\n    )\\n}\\n```\\n\\n\ud83d\udc49 Ergebnis:\\n\\n* **API-Interfaces** als Kotlin-Interfaces (Controller-Skeletons)\\n* **DTOs** im `model`-Package\\n\\n---\\n\\n## \ud83d\udea7 Lessons Learned\\n\\n### 1. Interface-Only ist Gold wert\\n\\n* Nur Interfaces generieren, Implementierung bleibt **sauber im eigenen Code**.\\n* Keine Merge-Konflikte beim erneuten Generieren.\\n\\n### 2. DTOs strikt nutzen\\n\\n* DTOs aus `model` sind **Transport-Objekte** \u2013 keine Business-Entities.\\n* Vermeide \u201esmarte\u201c Logik in DTOs, halte sie flach.\\n\\n### 3. Versionierung & Backward Compatibility\\n\\n* OpenAPI als **Single Source of Truth** in Git versionieren.\\n* Breaking Changes nur mit neuer API-Version (`/v2/...`).\\n\\n### 4. CI/CD-Checks\\n\\n* OpenAPI Spec validieren in jedem PR (`spectral lint`).\\n* Codegen im CI pr\xfcfen, ob alles aktuell ist (`git diff` auf generated code).\\n\\n---\\n\\n## \ud83d\udce6 Client-Generierung\\n\\nMit OpenAPI Generator lassen sich auch **Clients** f\xfcr andere Sprachen erstellen:\\n\\n```bash\\nopenapi-generator-cli generate \\\\\\n  -i api/openapi.yaml \\\\\\n  -g typescript-fetch \\\\\\n  -o clients/ts\\n```\\n\\n* Frontend nutzt `typescript-fetch` oder `typescript-axios`.\\n* Andere Services k\xf6nnen `java`, `python`, `go` SDKs beziehen.\\n* Einheitliche API garantiert Konsistenz \xfcber den Stack hinweg.\\n\\n---\\n\\n## \ud83d\udd17 Mini-Beispiel: User API End-to-End\\n\\n### 1. OpenAPI Spec (gek\xfcrzt)\\n\\n**`api/openapi.yaml`**\\n\\n```yaml\\nopenapi: 3.0.3\\ninfo:\\n  title: User API\\n  version: 1.0.0\\npaths:\\n  /users/{id}:\\n    get:\\n      summary: Get user by ID\\n      parameters:\\n        - in: path\\n          name: id\\n          required: true\\n          schema:\\n            type: string\\n            format: uuid\\n      responses:\\n        \'200\':\\n          description: OK\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/User\'\\n        \'404\':\\n          description: Not Found\\ncomponents:\\n  schemas:\\n    User:\\n      type: object\\n      properties:\\n        id:\\n          type: string\\n          format: uuid\\n        name:\\n          type: string\\n```\\n\\n### 2. Generiertes Interface (gek\xfcrzt)\\n\\n**`build/generated/com/example/api/UsersApi.kt`**\\n\\n```kotlin\\npackage com.example.api\\n\\nimport com.example.api.model.User\\nimport org.springframework.http.ResponseEntity\\nimport org.springframework.web.bind.annotation.PathVariable\\n\\ninterface UsersApi {\\n    fun getUserById(@PathVariable(\\"id\\") id: java.util.UUID): ResponseEntity<User>\\n}\\n```\\n\\n### 3. Kotlin-Implementierung\\n\\n**`src/main/kotlin/com/example/controller/UserController.kt`**\\n\\n```kotlin\\npackage com.example.controller\\n\\nimport com.example.api.UsersApi\\nimport com.example.api.model.User\\nimport org.springframework.http.ResponseEntity\\nimport org.springframework.web.bind.annotation.RestController\\nimport java.util.UUID\\n\\n@RestController\\nclass UserController : UsersApi {\\n    override fun getUserById(id: UUID): ResponseEntity<User> {\\n        val user = if (id.toString().startsWith(\\"a\\")) {\\n            User(id = id.toString(), name = \\"Alice\\")\\n        } else null\\n\\n        return user?.let { ResponseEntity.ok(it) }\\n            ?: ResponseEntity.notFound().build()\\n    }\\n}\\n```\\n\\n\ud83d\udc49 Flow: **Spec \u2192 Codegen \u2192 Interface \u2192 Implementierung**. Alle Teams nutzen dieselbe API-Definition.\\n\\n---\\n\\n## \ud83d\udccc Best Practices\\n\\n* **Keep the spec small**: nicht alles upfront modellieren, sondern inkrementell erweitern.\\n* **Namen konsistent**: API Paths, Models, Enums \u2192 konsistente Namenskonvention.\\n* **Sicherheit**: Security-Schemes (OAuth2, Bearer JWT) gleich in der Spec definieren.\\n* **Doku**: Nutze Swagger UI direkt im Service \u2013 Entwickler haben sofort Feedback.\\n\\n<Admonition type=\\"tip\\" title=\\"API-First lohnt sich\\">\\nDer Mehraufwand am Anfang zahlt sich mehrfach aus: Konsistente Schnittstellen, weniger Reibung zwischen Teams, schnellere Entwicklung.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nAPI-First mit OpenAPI und Kotlin + Spring Boot bedeutet: **erst Schnittstelle, dann Code**.\\nMit Generatoren f\xfcr Stubs & Clients wird der Prozess reproduzierbar, die Doku bleibt immer aktuell und Microservices k\xf6nnen schneller integriert werden."},{"id":"terraform-patterns-aks-azure","metadata":{"permalink":"/blog/terraform-patterns-aks-azure","source":"@site/blog/2025-02-03-terraform-patterns.md","title":"Terraform Patterns f\xfcr AKS & Azure","description":"Erfahrungen mit modularen Terraform-Setups f\xfcr AKS \u2013 von Modul-Design \xfcber RBAC bis zu Network Policies und CI/CD.","date":"2025-02-03T00:00:00.000Z","tags":[{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform"},{"inline":false,"label":"AKS","permalink":"/blog/tags/aks","description":"Azure Kubernetes Service"},{"inline":false,"label":"Azure","permalink":"/blog/tags/azure","description":"Azure"},{"inline":false,"label":"RBAC","permalink":"/blog/tags/rbac","description":"Role-Based Access Control"},{"inline":false,"label":"Network Policy","permalink":"/blog/tags/network-policy","description":"Network Policy"},{"inline":false,"label":"Modules","permalink":"/blog/tags/modules","description":"Modules"},{"inline":false,"label":"CI/CD","permalink":"/blog/tags/cicd","description":"Continuous Integration and Continuous Deployment"}],"readingTime":13.33,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"terraform-patterns-aks-azure","title":"Terraform Patterns f\xfcr AKS & Azure","authors":"brigitte","tags":["terraform","aks","azure","rbac","network-policy","modules","cicd"],"date":"2025-02-03T00:00:00.000Z","description":"Erfahrungen mit modularen Terraform-Setups f\xfcr AKS \u2013 von Modul-Design \xfcber RBAC bis zu Network Policies und CI/CD."},"unlisted":false,"prevItem":{"title":"API-First mit Spring Boot & Kotlin","permalink":"/blog/api-first-springboot-kotlin"},"nextItem":{"title":"AKS Node Selection: Physische Pools vs. Virtual Nodes","permalink":"/blog/aks-node-selection"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nAKS-Projekte wachsen schnell: **Cluster, Node Pools, Identities, Netzwerke, ACR, Policies** \u2013 und pro Umgebung (dev/test/prod) variieren Parameter. Ohne Struktur wird die Codebasis fragil. In diesem Beitrag zeige ich **bew\xe4hrte Terraform-Patterns** f\xfcr Azure & AKS aus Projekten, inkl. **RBAC**- und **Network-Policy**-Fallstricken.\\n\x3c!--truncate--\x3e\\n---\\n\\n## \ud83e\uddf1 Modul-Architektur: Trennen nach Verantwortlichkeiten\\n\\n**Ziel:** Wiederverwendbare, klar geschnittene Module statt eines \u201eMonolithen\u201c.\\n\\n```text\\ninfra/\\n\u251c\u2500 modules/\\n\u2502  \u251c\u2500 network/                 # VNet, Subnets, NSGs, UDR/NAT\\n\u2502  \u251c\u2500 aks/                     # AKS-Cluster + Pools\\n\u2502  \u251c\u2500 identity/                # UAMI/MI + Role Assignments\\n\u2502  \u251c\u2500 acr/                     # Container Registry\\n\u2502  \u251c\u2500 monitoring/              # Log Analytics, Insights\\n\u2502  \u251c\u2500 policies/                # Azure Policy + AKS Add-Ons\\n\u2502  \u2514\u2500 dns/                     # Private DNS Zonen\\n\u251c\u2500 env/\\n\u2502  \u251c\u2500 dev/\\n\u2502  \u2502  \u251c\u2500 main.tf               # Zusammensetzen der Module\\n\u2502  \u2502  \u251c\u2500 variables.tfvars\\n\u2502  \u2502  \u2514\u2500 backend.tf            # Remote State\\n\u2502  \u2514\u2500 prod/\\n\u2502     \u251c\u2500 ...\\n\u2514\u2500 global/\\n   \u2514\u2500 rg.tf                    # Ressourcengruppen, Tags, Management\\n```\\n\\n**Pattern:** Environments sind **Kompositionen** aus Modulen. Jedes Modul besitzt eine **klare API** (Inputs/Outputs) und minimale Seiteneffekte.\\n\\n<Admonition type=\\"tip\\" title=\\"Keep Inputs simple\\">\\nVermeide riesige, verschachtelte `object`-Variablen. Lieber mehrere flache Inputs mit Defaults \u2013 das reduziert `Unknown`-Diffs und erleichtert Upgrades.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udd27 Beispiel: AKS-Modul (Interface)\\n\\n```hcl\\nvariable \\"name\\" { type = string }\\nvariable \\"location\\" { type = string }\\nvariable \\"resource_group_name\\" { type = string }\\nvariable \\"kubernetes_version\\" { type = string }\\nvariable \\"network_profile\\" {\\n  type = object({\\n    plugin           = string   # azure, kubenet, cni_overlay\\n    pod_cidr         = optional(string)\\n    service_cidr     = string\\n    dns_service_ip   = string\\n    outbound_type    = string   # loadBalancer, userDefinedRouting, managedNATGateway\\n  })\\n}\\nvariable \\"enable_azure_rbac\\" { type = bool, default = true }\\nvariable \\"aad_admin_group_object_ids\\" { type = list(string), default = [] }\\nvariable \\"system_node_pool\\" {\\n  type = object({\\n    name       = string\\n    vm_size    = string\\n    min_count  = number\\n    max_count  = number\\n    os_sku     = optional(string, \\"Ubuntu\\")\\n  })\\n}\\nvariable \\"user_node_pools\\" {\\n  type = list(object({\\n    name       = string\\n    vm_size    = string\\n    min_count  = number\\n    max_count  = number\\n    taints     = optional(list(string), [])\\n    labels     = optional(map(string), {})\\n    mode       = optional(string, \\"User\\")\\n  }))\\n  default = []\\n}\\noutput \\"kubelet_identity_principal_id\\" { value = azurerm_kubernetes_cluster.this.kubelet_identity[0].object_id }\\noutput \\"cluster_id\\" { value = azurerm_kubernetes_cluster.this.id }\\n```\\n\\n> **Hinweis:** Abh\xe4ngig von Provider-Versionen unterscheiden sich Block\u2011Namen/Flags. Kapsle Version-Spezifika **im Modul** und biete stabile Inputs nach au\xdfen.\\n\\n---\\n\\n## \ud83e\udeaa RBAC & Identit\xe4ten: h\xe4ufige Fallstricke\\n\\n### 1) Azure RBAC vs. Kubernetes RBAC\\n\\n* **Azure RBAC f\xfcr Kubernetes** (\\"AKS-managed AAD\\") vereinfacht die AuthN/AuthZ, aber **Mapping & Propagation** dauern ggf. Sekunden/Minuten.\\n* **Pattern:** Lege **AAD-Gruppen** f\xfcr Cluster\u2011Rollen an (z.\u202fB. `aks-admins`, `aks-devs`) und reiche deren Objekt\u2011IDs als Modul\u2011Input durch.\\n\\n```hcl\\n# Pseudocode \u2013 Modul nutzt diese IDs\\nvariable \\"aad_admin_group_object_ids\\" { type = list(string) }\\n# Im Cluster\u2011Block: AAD/RBAC aktivieren und Gruppen als Admins registrieren\\n```\\n\\n**Anti\u2011Pattern:** Einzelne User direkt hinterlegen \u2192 schwer wartbar, keine Rotation.\\n\\n### 2) Kubelet/ACR Berechtigungen\\n\\n* Damit Nodes Images ziehen k\xf6nnen: `AcrPull` auf **ACR** f\xfcr die **Kubelet-Identity**.\\n* Zus\xe4tzlich: Build/Push\u2011Pipeline \u2192 `AcrPush` f\xfcr CI\u2011Service\u2011Principal oder UAMI.\\n\\n```hcl\\nresource \\"azurerm_role_assignment\\" \\"kubelet_acr_pull\\" {\\n  scope                = azurerm_container_registry.acr.id\\n  role_definition_name = \\"AcrPull\\"\\n  principal_id         = module.aks.kubelet_identity_principal_id\\n}\\n```\\n\\n### 3) Netzwerk\u2011Rollen\\n\\n* Bei **UDR/NAT Gateway**: `Network Contributor` auf Subnet/RouteTable f\xfcr die **AKS\u2011MI** (Cluster Identity) \u2013 sonst schl\xe4gt Provisioning/Scale fehl.\\n\\n<Admonition type=\\"caution\\" title=\\"Eventual Consistency\\">\\nRole Assignments sind **eventual consistent**. Plane Wartezeiten/`depends_on` ein oder nutze ein Retry\u2011Wrapper\u2011Modul.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udd10 Network Policies: Praxis statt Theorie\\n\\n**Ziel:** Default\u2011Deny auf Pod\u2011Ebene + gezielte Allow\u2011Regeln.\\n\\n* **CNI/Policy-Matrix** unterscheidet sich je nach AKS\u2011Version: Azure CNI (Classic/Overlay) & Kubenet verhalten sich unterschiedlich.\\n* **Pattern:** Parametrisiere Policy\u2011Engine (`azure`, `calico`) als Modul\u2011Input und generiere **Basisregeln** zentral.\\n\\n### Baseline (Namespaceseitig) \u2013 Default Deny\\n\\n```yaml\\napiVersion: networking.k8s.io/v1\\nkind: NetworkPolicy\\nmetadata:\\n  name: default-deny\\n  namespace: myns\\nspec:\\n  podSelector: {}\\n  policyTypes: [Ingress, Egress]\\n```\\n\\n### Allow: Ingress vom Ingress-Controller + DNS Egress\\n\\n```yaml\\napiVersion: networking.k8s.io/v1\\nkind: NetworkPolicy\\nmetadata:\\n  name: allow-ingress-from-gateway\\n  namespace: myns\\nspec:\\n  podSelector:\\n    matchLabels:\\n      app: web\\n  ingress:\\n    - from:\\n        - namespaceSelector:\\n            matchLabels:\\n              kubernetes.io/metadata.name: ingress-nginx\\n  egress:\\n    - to:\\n        - namespaceSelector:\\n            matchLabels:\\n              kubernetes.io/metadata.name: kube-system\\n      ports:\\n        - protocol: UDP\\n          port: 53\\n```\\n\\n<Admonition type=\\"note\\" title=\\"Test\\">\\nValidiere Policies mit `netshoot`, `curl`, `dig` und CI\u2011Checks (z.\u202fB. Kyverno/OPA\u2011Constraints). Automatisierte Smoke\u2011Tests sind Gold wert.\\n</Admonition>\\n\\n---\\n\\n## \ud83c\udf10 Netzwerk-Setup: bew\xe4hrte Optionen\\n\\n* **Outbound**: `managedNATGateway` oder `userDefinedRouting` mit Azure Firewall.\\n* **Private Cluster**: Private Endpoint + DNS Zonen, Jump\u2011Host/Bastion f\xfcr `kubectl`.\\n* **Ingress**: AGIC oder NGINX; bei Private Cluster \u2192 interne LoadBalancer/Private Link.\\n* **Egress\u2011Lockdown**: Azure Firewall DNAT/Anwendungsregeln; Policies f\xfcr verbotene Public\u2011IPs.\\n\\n**Pattern:** Netz\u2011Modul liefert **Subnet\u2011IDs**/Routen als Outputs an das AKS\u2011Modul; keine zirkul\xe4ren Abh\xe4ngigkeiten.\\n\\n---\\n\\n## \ud83e\uddea Environments, Workspaces & State\\n\\n* **Remote State** in Azure Storage (Blob) mit **State\u2011Locking** via Storage Lease.\\n* **One workspace per environment** (z.\u202fB. `dev`, `prod`) \u2013 kein Mischen.\\n* **tfvars** pro Umgebung + `locals` f\xfcr abgeleitete Werte (Tags, Namenskonventionen, CIDRs).\\n\\n```hcl\\n# backend.tf (je Env)\\nterraform {\\n  backend \\"azurerm\\" {}\\n  required_version = \\">= 1.7.0\\"\\n  required_providers {\\n    azurerm = {\\n      source  = \\"hashicorp/azurerm\\"\\n      version = \\"~> 3.100\\"\\n    }\\n  }\\n}\\n```\\n\\n<Admonition type=\\"tip\\" title=\\"Namenskonventionen\\">\\nEin `locals.naming`\u2011Block vereinheitlicht Ressourcennamen \xfcber alle Module (Prefix/Env/Location).\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udea6 CI/CD & Sicherheit\\n\\n* **Pipeline\u2011Matrix** pro Umfeld (Plan/Apply) mit manueller Freigabe f\xfcr prod.\\n* **Pre\u2011Commit**: `terraform fmt`, `tflint`, `tfsec`/`checkov`, `terrascan`.\\n* **Drift Detection**: `terraform plan` on schedule \u2192 Slack/Teams\u2011Report.\\n* **Plan\u2011Artefakte** signieren/archivieren.\\n* **Provider\u2011Pins** + Renovate/Bump PRs \u2192 reproduzierbare Builds.\\n\\n**Pattern:** `make plan ENV=dev` ruft `terraform workspace select dev` + `-var-file=env/dev/variables.tfvars` auf \u2013 identische Befehle lokal und in CI.\\n\\n---\\n\\n## \ud83d\udce6 Komplettes AKS-Beispiel (gek\xfcrzt)\\n\\n```hcl\\nmodule \\"network\\" {\\n  source              = \\"../modules/network\\"\\n  name                = local.naming.net\\n  location            = var.location\\n  address_space       = [\\"10.40.0.0/16\\"]\\n  subnets = {\\n    aks_nodes = {\\n      prefix = \\"10.40.1.0/24\\"\\n      nsg_rules = [\\"deny_internet_in\\", \\"allow_vnet\\"]\\n    }\\n  }\\n}\\n\\nmodule \\"acr\\" {\\n  source              = \\"../modules/acr\\"\\n  name                = local.naming.acr\\n  location            = var.location\\n  sku                 = \\"Standard\\"\\n}\\n\\nmodule \\"aks\\" {\\n  source                  = \\"../modules/aks\\"\\n  name                    = local.naming.aks\\n  location                = var.location\\n  resource_group_name     = azurerm_resource_group.rg.name\\n  kubernetes_version      = var.k8s_version\\n  network_profile = {\\n    plugin         = \\"azure\\"\\n    service_cidr   = \\"10.41.0.0/16\\"\\n    dns_service_ip = \\"10.41.0.10\\"\\n    outbound_type  = \\"managedNATGateway\\"\\n  }\\n  system_node_pool = {\\n    name      = \\"sys\\"\\n    vm_size   = \\"Standard_D4s_v5\\"\\n    min_count = 1\\n    max_count = 3\\n  }\\n  user_node_pools = [\\n    {\\n      name = \\"user\\"\\n      vm_size = \\"Standard_D8s_v5\\"\\n      min_count = 2\\n      max_count = 10\\n      labels = { \\"kubernetes.azure.com/mode\\" = \\"user\\" }\\n    }\\n  ]\\n  enable_azure_rbac            = true\\n  aad_admin_group_object_ids   = var.aad_admin_groups\\n}\\n\\n# Role Assignment f\xfcr Kubelet \u2192 ACR Pull\\nresource \\"azurerm_role_assignment\\" \\"kubelet_acr\\" {\\n  scope                = module.acr.id\\n  role_definition_name = \\"AcrPull\\"\\n  principal_id         = module.aks.kubelet_identity_principal_id\\n}\\n```\\n\\n---\\n\\n## \ud83e\udded Checkliste \u2013 Was gerne schiefgeht\\n\\n* [ ] `AcrPull` f\xfcr **Kubelet** vergessen \u2192 ImagePullBackOff\\n* [ ] Subnet/RT/NAT Rechte fehlen \u2192 AKS Provisioning h\xe4ngt\\n* [ ] Azure RBAC Gruppen nicht propagiert \u2192 Admins k\xf6nnen nicht joinen (abwarten/retry)\\n* [ ] Network Policies greifen nicht (Policy\u2011Engine/CNI passt nicht zur Cluster\u2011Config)\\n* [ ] Private DNS nicht konfiguriert \u2192 Control Plane/Ingress/ACR nicht erreichbar\\n* [ ] Provider\u2011Upgrade ohne Modul\u2011Kapselung \u2192 Breaking Changes \xfcberall\\n\\n<Admonition type=\\"caution\\" title=\\"Production Readiness\\">\\nVor Prod\u2011Rollout: e2e\u2011Tests (Deployments, Pull aus ACR, Ingress, DNS, Policy\u2011Smoke), Loadtests, Failover (Node Drain, Pool\u2011Scaling), Backup/Restore (etcd/Velero), Secrets\u2011Pfad (Key Vault + CSI).\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nEin **modulares Terraform\u2011Design** f\xfcr AKS zahlt sich aus: klarere Zust\xe4ndigkeiten, weniger Drift, reproduzierbare Builds und kontrollierte Sicherheit. Mit sauberem RBAC, durchdachtem Netzwerk\u2011Layout und automatisierten Checks bleibt die Plattform **skalierbar** und **betriebsstabil**.\\n\\n---\\n\\n## \ud83d\udce6 Vollst\xe4ndiges AKS\u2011Modul (Beispiel)\\n\\n**`modules/aks/main.tf`**\\n\\n```hcl\\nresource \\"azurerm_kubernetes_cluster\\" \\"this\\" {\\n  name                = var.name\\n  location            = var.location\\n  resource_group_name = var.resource_group_name\\n  dns_prefix          = \\"${var.name}-dns\\"\\n  kubernetes_version  = var.kubernetes_version\\n\\n  identity {\\n    type = \\"SystemAssigned\\"\\n  }\\n\\n  default_node_pool {\\n    name                = var.system_node_pool.name\\n    vm_size             = var.system_node_pool.vm_size\\n    min_count           = var.system_node_pool.min_count\\n    max_count           = var.system_node_pool.max_count\\n    enable_auto_scaling = true\\n    os_sku              = var.system_node_pool.os_sku\\n    mode                = \\"System\\"\\n  }\\n\\n  dynamic \\"agent_pool_profile\\" {\\n    for_each = var.user_node_pools\\n    content {\\n      name                = agent_pool_profile.value.name\\n      vm_size             = agent_pool_profile.value.vm_size\\n      min_count           = agent_pool_profile.value.min_count\\n      max_count           = agent_pool_profile.value.max_count\\n      enable_auto_scaling = true\\n      mode                = lookup(agent_pool_profile.value, \\"mode\\", \\"User\\")\\n      node_labels         = lookup(agent_pool_profile.value, \\"labels\\", null)\\n      node_taints         = lookup(agent_pool_profile.value, \\"taints\\", null)\\n    }\\n  }\\n\\n  role_based_access_control_enabled = var.enable_azure_rbac\\n\\n  azure_active_directory_role_based_access_control {\\n    managed                = true\\n    admin_group_object_ids = var.aad_admin_group_object_ids\\n  }\\n\\n  network_profile {\\n    network_plugin     = var.network_profile.plugin\\n    service_cidr       = var.network_profile.service_cidr\\n    dns_service_ip     = var.network_profile.dns_service_ip\\n    pod_cidr           = try(var.network_profile.pod_cidr, null)\\n    outbound_type      = var.network_profile.outbound_type\\n  }\\n}\\n\\noutput \\"kubelet_identity_principal_id\\" {\\n  value = azurerm_kubernetes_cluster.this.kubelet_identity[0].object_id\\n}\\n\\noutput \\"id\\" {\\n  value = azurerm_kubernetes_cluster.this.id\\n}\\n```\\n\\n**`modules/aks/variables.tf`**\\n\\n```hcl\\nvariable \\"name\\" { type = string }\\nvariable \\"location\\" { type = string }\\nvariable \\"resource_group_name\\" { type = string }\\nvariable \\"kubernetes_version\\" { type = string }\\n\\nvariable \\"network_profile\\" {\\n  type = object({\\n    plugin         = string\\n    service_cidr   = string\\n    dns_service_ip = string\\n    pod_cidr       = optional(string)\\n    outbound_type  = string\\n  })\\n}\\n\\nvariable \\"enable_azure_rbac\\" { type = bool }\\nvariable \\"aad_admin_group_object_ids\\" { type = list(string) }\\n\\nvariable \\"system_node_pool\\" {\\n  type = object({\\n    name      = string\\n    vm_size   = string\\n    min_count = number\\n    max_count = number\\n    os_sku    = optional(string, \\"Ubuntu\\")\\n  })\\n}\\n\\nvariable \\"user_node_pools\\" {\\n  type = list(object({\\n    name      = string\\n    vm_size   = string\\n    min_count = number\\n    max_count = number\\n    mode      = optional(string, \\"User\\")\\n    labels    = optional(map(string))\\n    taints    = optional(list(string))\\n  }))\\n  default = []\\n}\\n```\\n\\n---\\n\\n## \ud83d\ude80 Azure DevOps Pipeline f\xfcr Terraform AKS\\n\\n**`.azure-pipelines/terraform-aks.yml`**\\n\\n```yaml\\ntrigger:\\n  branches:\\n    include:\\n      - main\\n\\nvariables:\\n  TF_VERSION: \'1.7.5\'\\n  AZURE_SUBSCRIPTION: \'MyServiceConnection\'\\n  ENVIRONMENT: \'dev\'\\n\\nstages:\\n  - stage: validate\\n    displayName: \\"Terraform Validate & Lint\\"\\n    jobs:\\n      - job: lint\\n        pool:\\n          vmImage: \'ubuntu-latest\'\\n        steps:\\n          - task: UseTerraform@0\\n            inputs:\\n              terraformVersion: $(TF_VERSION)\\n          - script: |\\n              terraform fmt -check -recursive\\n              terraform init -backend=false\\n              terraform validate\\n            displayName: \\"Terraform fmt & validate\\"\\n          - script: |\\n              curl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash\\n              tflint --recursive\\n            displayName: \\"Run TFLint\\"\\n\\n  - stage: plan\\n    displayName: \\"Terraform Plan\\"\\n    dependsOn: validate\\n    jobs:\\n      - job: plan\\n        pool:\\n          vmImage: \'ubuntu-latest\'\\n        steps:\\n          - task: UseTerraform@0\\n            inputs:\\n              terraformVersion: $(TF_VERSION)\\n          - task: TerraformCLI@0\\n            displayName: \\"Terraform Init\\"\\n            inputs:\\n              command: \'init\'\\n              backendType: \'azurerm\'\\n              backendServiceArm: $(AZURE_SUBSCRIPTION)\\n              ensureBackend: true\\n              workingDirectory: \'infra/env/$(ENVIRONMENT)\'\\n          - task: TerraformCLI@0\\n            displayName: \\"Terraform Plan\\"\\n            inputs:\\n              command: \'plan\'\\n              environmentServiceName: $(AZURE_SUBSCRIPTION)\\n              workingDirectory: \'infra/env/$(ENVIRONMENT)\'\\n              vars: |\\n                environment=$(ENVIRONMENT)\\n          - publish: $(System.DefaultWorkingDirectory)/infra/env/$(ENVIRONMENT)/tfplan\\n            artifact: tfplan\\n\\n  - stage: apply\\n    displayName: \\"Terraform Apply\\"\\n    dependsOn: plan\\n    condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\\n    jobs:\\n      - deployment: apply\\n        environment: aks-$(ENVIRONMENT)\\n        pool:\\n          vmImage: \'ubuntu-latest\'\\n        strategy:\\n          runOnce:\\n            deploy:\\n              steps:\\n                - task: UseTerraform@0\\n                  inputs:\\n                    terraformVersion: $(TF_VERSION)\\n                - download: current\\n                  artifact: tfplan\\n                - task: TerraformCLI@0\\n                  displayName: \\"Terraform Apply\\"\\n                  inputs:\\n                    command: \'apply\'\\n                    environmentServiceName: $(AZURE_SUBSCRIPTION)\\n                    workingDirectory: \'infra/env/$(ENVIRONMENT)\'\\n                    commandOptions: \\"tfplan\\"\\n```\\n\\n---\\n\\n## \ud83d\udccc Ergebnis\\n\\nMit einem **klar gekapselten AKS-Modul** und einer **CI/CD-Pipeline in Azure DevOps** erh\xe4ltst du:\\n\\n* reproduzierbare Cluster-Deployments\\n* automatisierte Validierung (fmt, validate, lint)\\n* Plan-Review mit Artefakten\\n* manuelles oder automatisiertes Apply mit Service Connection\\n* einfache Erweiterbarkeit (Drift Detection, Security Scans)\\n\\n---\\n\\n## \ud83e\udde9 Produktionsreifes AKS\u2011Modul (Terraform)\\n\\n> Struktur (als Beispiel):\\n>\\n> ```text\\n> modules/aks/\\n> \u251c\u2500 main.tf\\n> \u251c\u2500 variables.tf\\n> \u251c\u2500 outputs.tf\\n> \u2514\u2500 README.md\\n> ```\\n\\n**`modules/aks/variables.tf`**\\n\\n```hcl\\nvariable \\"name\\" { type = string }\\nvariable \\"location\\" { type = string }\\nvariable \\"resource_group_name\\" { type = string }\\n\\nvariable \\"kubernetes_version\\" { type = string }\\n\\nvariable \\"tags\\" { type = map(string), default = {} }\\n\\nvariable \\"identity_type\\" {\\n  description = \\"system | user\\"\\n  type        = string\\n  default     = \\"system\\"\\n  validation {\\n    condition     = contains([\\"system\\", \\"user\\"], var.identity_type)\\n    error_message = \\"identity_type must be \'system\' or \'user\'\\"\\n  }\\n}\\n\\nvariable \\"user_assigned_identity_ids\\" {\\n  description = \\"Only used when identity_type=user\\"\\n  type        = list(string)\\n  default     = []\\n}\\n\\nvariable \\"network_profile\\" {\\n  type = object({\\n    plugin           = string                    # azure | kubenet | cni_overlay\\n    service_cidr     = string\\n    dns_service_ip   = string\\n    pod_cidr         = optional(string)\\n    outbound_type    = optional(string, \\"managedNATGateway\\") # loadBalancer | userDefinedRouting | managedNATGateway\\n    network_policy   = optional(string, null)   # azure | calico | null\\n  })\\n}\\n\\nvariable \\"private_cluster_enabled\\" { type = bool, default = false }\\nvariable \\"api_server_authorized_ip_ranges\\" { type = list(string), default = [] }\\n\\nvariable \\"aad_admin_group_object_ids\\" { type = list(string), default = [] }\\nvariable \\"enable_azure_rbac\\" { type = bool, default = true }\\n\\nvariable \\"oms_workspace_resource_id\\" { type = string, default = null }\\nvariable \\"enable_azure_policy_addon\\" { type = bool, default = false }\\n\\nvariable \\"system_node_pool\\" {\\n  type = object({\\n    name               = string\\n    vm_size            = string\\n    min_count          = number\\n    max_count          = number\\n    os_disk_size_gb    = optional(number, 128)\\n    os_sku             = optional(string, \\"Ubuntu\\")\\n    node_labels        = optional(map(string), {})\\n    node_taints        = optional(list(string), [])\\n    zones              = optional(list(string), null)\\n  })\\n}\\n\\nvariable \\"user_node_pools\\" {\\n  description = \\"List of additional user pools\\"\\n  type = list(object({\\n    name               = string\\n    vm_size            = string\\n    min_count          = number\\n    max_count          = number\\n    os_disk_size_gb    = optional(number, 128)\\n    os_sku             = optional(string, \\"Ubuntu\\")\\n    node_labels        = optional(map(string), {})\\n    node_taints        = optional(list(string), [])\\n    mode               = optional(string, \\"User\\")\\n    zones              = optional(list(string), null)\\n  }))\\n  default = []\\n}\\n```\\n\\n**`modules/aks/main.tf`**\\n\\n```hcl\\n# Hinweis: Provider-Konfiguration (azurerm) wird au\xdferhalb des Moduls gesetzt.\\n\\nlocals {\\n  identity_block = var.identity_type == \\"user\\" ? {\\n    type         = \\"UserAssigned\\"\\n    identity_ids = var.user_assigned_identity_ids\\n  } : {\\n    type = \\"SystemAssigned\\"\\n  }\\n}\\n\\nresource \\"azurerm_kubernetes_cluster\\" \\"this\\" {\\n  name                = var.name\\n  location            = var.location\\n  resource_group_name = var.resource_group_name\\n  kubernetes_version  = var.kubernetes_version\\n  dns_prefix          = replace(var.name, \\".\\", \\"-\\")\\n\\n  identity {\\n    type         = local.identity_block.type\\n    identity_ids = try(local.identity_block.identity_ids, null)\\n  }\\n\\n  default_node_pool {\\n    name                 = var.system_node_pool.name\\n    vm_size              = var.system_node_pool.vm_size\\n    orchestrator_version = var.kubernetes_version\\n    min_count            = var.system_node_pool.min_count\\n    max_count            = var.system_node_pool.max_count\\n    enable_auto_scaling  = true\\n    os_sku               = var.system_node_pool.os_sku\\n    os_disk_size_gb      = var.system_node_pool.os_disk_size_gb\\n    node_labels          = var.system_node_pool.node_labels\\n    node_taints          = var.system_node_pool.node_taints\\n    zones                = var.system_node_pool.zones\\n    upgrade_settings {\\n      max_surge = \\"33%\\"\\n    }\\n  }\\n\\n  network_profile {\\n    network_plugin    = var.network_profile.plugin\\n    service_cidr      = var.network_profile.service_cidr\\n    dns_service_ip    = var.network_profile.dns_service_ip\\n    network_policy    = var.network_profile.network_policy\\n    outbound_type     = var.network_profile.outbound_type\\n    pod_cidr          = try(var.network_profile.pod_cidr, null)\\n  }\\n\\n  api_server_access_profile {\\n    authorized_ip_ranges = var.api_server_authorized_ip_ranges\\n  }\\n\\n  azure_active_directory_role_based_access_control {\\n    enabled                        = true\\n    azure_rbac_enabled             = var.enable_azure_rbac\\n    admin_group_object_ids         = var.aad_admin_group_object_ids\\n  }\\n\\n  # Add-ons\\n  dynamic \\"oms_agent\\" {\\n    for_each = var.oms_workspace_resource_id == null ? [] : [1]\\n    content {\\n      log_analytics_workspace_id = var.oms_workspace_resource_id\\n    }\\n  }\\n\\n  azure_policy_enabled        = var.enable_azure_policy_addon\\n  private_cluster_enabled     = var.private_cluster_enabled\\n\\n  sku_tier = \\"Paid\\" # Uptime SLA optional, anpassbar\\n\\n  tags = var.tags\\n}\\n\\n# Zus\xe4tzliche User Node Pools\\nresource \\"azurerm_kubernetes_cluster_node_pool\\" \\"user\\" {\\n  for_each = { for p in var.user_node_pools : p.name => p }\\n\\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.this.id\\n  name                  = each.value.name\\n  vm_size               = each.value.vm_size\\n  orchestrator_version  = var.kubernetes_version\\n  mode                  = try(each.value.mode, \\"User\\")\\n  min_count             = each.value.min_count\\n  max_count             = each.value.max_count\\n  enable_auto_scaling   = true\\n  os_disk_size_gb       = try(each.value.os_disk_size_gb, 128)\\n  os_sku                = try(each.value.os_sku, \\"Ubuntu\\")\\n  node_labels           = try(each.value.node_labels, {})\\n  node_taints           = try(each.value.node_taints, [])\\n  zones                 = try(each.value.zones, null)\\n\\n  tags = var.tags\\n}\\n```\\n\\n**`modules/aks/outputs.tf`**\\n\\n```hcl\\noutput \\"id\\" { value = azurerm_kubernetes_cluster.this.id }\\noutput \\"kubelet_identity_principal_id\\" {\\n  value = try(azurerm_kubernetes_cluster.this.kubelet_identity[0].object_id, null)\\n}\\noutput \\"principal_id\\" { # Cluster (control plane) MI bei SystemAssigned\\n  value = try(azurerm_kubernetes_cluster.this.identity[0].principal_id, null)\\n}\\noutput \\"host\\" { value = azurerm_kubernetes_cluster.this.kube_config[0].host }\\noutput \\"name\\" { value = azurerm_kubernetes_cluster.this.name }\\n```\\n\\n**`modules/aks/README.md`** (Kurz)\\n\\n```md\\nInputs kapseln AKS-Details (RBAC, Network, Private Cluster). Provider au\xdferhalb konfigurieren. Role Assignments (ACR Pull, Subnet/RouteTable) au\xdferhalb setzen.\\n```\\n\\n---\\n\\n## \ud83d\udd01 Azure DevOps Pipeline (Terraform Plan/Apply, Multi\u2011Env)\\n\\n> Voraussetzungen\\n>\\n> * Azure DevOps **Service Connection** (ARM) mit **Workload Identity/Federated Credentials** f\xfcr Subscription/Resource Group.\\n> * Azure Storage Backend f\xfcr Terraform State (Container + Blob Locking via Lease).\\n> * Optional: Variable Groups f\xfcr `ARM_*`/Backend\u2011Parameter.\\n\\n**`azure-pipelines.yml`**\\n\\n```yaml\\ntrigger:\\n  branches:\\n    include: [ main ]\\npr:\\n  branches:\\n    include: [ main, feature/* ]\\n\\nvariables:\\n  TF_VERSION: \'1.8.5\'\\n  PROVIDER_AZURERM: \'~> 3.113\'\\n  # Backend (per Variable Group setzbar)\\n  TF_BACKEND_RG: \'rg-tfstate\'\\n  TF_BACKEND_SA: \'sttfstate1234\'\\n  TF_BACKEND_CONTAINER: \'tfstate\'\\n  TF_BACKEND_KEY: \'$(Build.Repository.Name).$(System.StageName).tfstate\'\\n\\nstages:\\n- stage: Validate\\n  displayName: \\"Validate & Security Checks\\"\\n  jobs:\\n  - job: validate\\n    pool: { vmImage: \'ubuntu-latest\' }\\n    steps:\\n    - checkout: self\\n    - task: Bash@3\\n      displayName: \\"Install Terraform $(TF_VERSION)\\"\\n      inputs:\\n        targetType: \'inline\'\\n        script: |\\n          curl -sLo tf.zip https://releases.hashicorp.com/terraform/$(TF_VERSION)/terraform_$(TF_VERSION)_linux_amd64.zip\\n          sudo unzip -o tf.zip -d /usr/local/bin\\n          terraform -version\\n    - task: Bash@3\\n      displayName: \\"Terraform fmt & init\\"\\n      env:\\n        ARM_USE_OIDC: true\\n      inputs:\\n        targetType: \'inline\'\\n        script: |\\n          cd infra/env/dev\\n          terraform init \\\\\\n            -backend-config=\\"resource_group_name=$(TF_BACKEND_RG)\\" \\\\\\n            -backend-config=\\"storage_account_name=$(TF_BACKEND_SA)\\" \\\\\\n            -backend-config=\\"container_name=$(TF_BACKEND_CONTAINER)\\" \\\\\\n            -backend-config=\\"key=$(TF_BACKEND_KEY)\\"\\n          terraform fmt -check -recursive\\n          terraform validate\\n    - task: Bash@3\\n      displayName: \\"tflint / tfsec\\"\\n      inputs:\\n        targetType: \'inline\'\\n        script: |\\n          curl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash\\n          tflint --version\\n          tflint -f compact || true\\n          curl -sL https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | bash\\n          tfsec . || true\\n\\n- stage: Plan\\n  displayName: \\"Plan (Dev)\\"\\n  dependsOn: Validate\\n  jobs:\\n  - job: plan_dev\\n    displayName: \\"terraform plan dev\\"\\n    pool: { vmImage: \'ubuntu-latest\' }\\n    steps:\\n    - checkout: self\\n    - task: AzureCLI@2\\n      displayName: \\"Terraform init+plan (OIDC)\\"\\n      inputs:\\n        azureSubscription: \'AZURE-SP-WI\'   # Name eurer Service Connection\\n        scriptType: bash\\n        scriptLocation: inlineScript\\n        inlineScript: |\\n          set -e\\n          cd infra/env/dev\\n          terraform init \\\\\\n            -backend-config=\\"resource_group_name=$(TF_BACKEND_RG)\\" \\\\\\n            -backend-config=\\"storage_account_name=$(TF_BACKEND_SA)\\" \\\\\\n            -backend-config=\\"container_name=$(TF_BACKEND_CONTAINER)\\" \\\\\\n            -backend-config=\\"key=$(TF_BACKEND_KEY)\\"\\n          terraform workspace select dev || terraform workspace new dev\\n          terraform plan -var-file=variables.tfvars -out=tfplan\\n    - publish: infra/env/dev/tfplan\\n      displayName: \\"Publish plan artifact\\"\\n      artifact: tfplan-dev\\n\\n- stage: Apply\\n  displayName: \\"Apply (Dev)\\"\\n  dependsOn: Plan\\n  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\\n  jobs:\\n  - deployment: apply_dev\\n    displayName: \\"terraform apply dev\\"\\n    environment: dev # optional: Environments mit Approvals sch\xfctzen\\n    strategy:\\n      runOnce:\\n        deploy:\\n          steps:\\n          - checkout: self\\n          - task: AzureCLI@2\\n            displayName: \\"Terraform init+apply\\"\\n            inputs:\\n              azureSubscription: \'AZURE-SP-WI\'\\n              scriptType: bash\\n              scriptLocation: inlineScript\\n              inlineScript: |\\n                set -e\\n                cd infra/env/dev\\n                terraform init \\\\\\n                  -backend-config=\\"resource_group_name=$(TF_BACKEND_RG)\\" \\\\\\n                  -backend-config=\\"storage_account_name=$(TF_BACKEND_SA)\\" \\\\\\n                  -backend-config=\\"container_name=$(TF_BACKEND_CONTAINER)\\" \\\\\\n                  -backend-config=\\"key=$(TF_BACKEND_KEY)\\"\\n                terraform workspace select dev || terraform workspace new dev\\n                terraform apply -auto-approve tfplan\\n\\n- stage: Plan_Prod\\n  displayName: \\"Plan (Prod)\\"\\n  dependsOn: Apply\\n  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\\n  jobs:\\n  - job: plan_prod\\n    pool: { vmImage: \'ubuntu-latest\' }\\n    steps:\\n    - checkout: self\\n    - task: AzureCLI@2\\n      displayName: \\"Plan prod\\"\\n      inputs:\\n        azureSubscription: \'AZURE-SP-WI\'\\n        scriptType: bash\\n        scriptLocation: inlineScript\\n        inlineScript: |\\n          set -e\\n          cd infra/env/prod\\n          terraform init \\\\\\n            -backend-config=\\"resource_group_name=$(TF_BACKEND_RG)\\" \\\\\\n            -backend-config=\\"storage_account_name=$(TF_BACKEND_SA)\\" \\\\\\n            -backend-config=\\"container_name=$(TF_BACKEND_CONTAINER)\\" \\\\\\n            -backend-config=\\"key=$(TF_BACKEND_KEY)\\"\\n          terraform workspace select prod || terraform workspace new prod\\n          terraform plan -var-file=variables.tfvars -out=tfplan\\n    - publish: infra/env/prod/tfplan\\n      artifact: tfplan-prod\\n\\n- stage: Apply_Prod\\n  displayName: \\"Apply (Prod)\\"\\n  dependsOn: Plan_Prod\\n  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\\n  jobs:\\n  - deployment: apply_prod\\n    displayName: \\"terraform apply prod\\"\\n    environment: prod # Enforce manual approval in ADO Environment\\n    strategy:\\n      runOnce:\\n        deploy:\\n          steps:\\n          - checkout: self\\n          - task: AzureCLI@2\\n            displayName: \\"Apply prod\\"\\n            inputs:\\n              azureSubscription: \'AZURE-SP-WI\'\\n              scriptType: bash\\n              scriptLocation: inlineScript\\n              inlineScript: |\\n                set -e\\n                cd infra/env/prod\\n                terraform init \\\\\\n                  -backend-config=\\"resource_group_name=$(TF_BACKEND_RG)\\" \\\\\\n                  -backend-config=\\"storage_account_name=$(TF_BACKEND_SA)\\" \\\\\\n                  -backend-config=\\"container_name=$(TF_BACKEND_CONTAINER)\\" \\\\\\n                  -backend-config=\\"key=$(TF_BACKEND_KEY)\\"\\n                terraform workspace select prod || terraform workspace new prod\\n                terraform apply -auto-approve tfplan\\n```\\n\\n### Hinweise & Best Practices\\n\\n* **OIDC/Federated Credentials:** Service Connection so konfigurieren, dass kein Secret n\xf6tig ist (kein Service Principal Passwort im Repo).\\n* **State pro Stage:** Der Key `$(System.StageName)` im Backend trennt dev/prod sauber.\\n* **Security Scans:** `tflint`/`tfsec` sind `|| true`, damit Warnungen den Build nicht hart brechen \u2013 in Prod optional erzwingen.\\n* **Approvals:** Azure DevOps **Environments** f\xfcr manuelle Freigaben zwischen Stufen nutzen.\\n* **Parallel Envs:** F\xfcr mehrere Envs `strategy: matrix` in Plan/Apply nutzen oder Envs als separate Stages definieren.\\n\\n---\\n\\n## \ud83d\udd17 Beispiel: Verwendung des AKS\u2011Moduls in `infra/env/dev/main.tf`\\n\\n```hcl\\nterraform {\\n  required_version = \\">= 1.8.0\\"\\n  required_providers {\\n    azurerm = {\\n      source  = \\"hashicorp/azurerm\\"\\n      version = \\"~> 3.113\\"\\n    }\\n  }\\n  backend \\"azurerm\\" {}\\n}\\n\\nprovider \\"azurerm\\" {\\n  features {}\\n  use_oidc = true\\n}\\n\\nlocals {\\n  tags = {\\n    env   = \\"dev\\"\\n    owner = \\"platform\\"\\n  }\\n}\\n\\nresource \\"azurerm_resource_group\\" \\"rg\\" {\\n  name     = \\"rg-aks-dev\\"\\n  location = var.location\\n  tags     = local.tags\\n}\\n\\nmodule \\"aks\\" {\\n  source              = \\"../../modules/aks\\"\\n  name                = \\"aks-dev-core\\"\\n  location            = var.location\\n  resource_group_name = azurerm_resource_group.rg.name\\n  kubernetes_version  = var.k8s_version\\n  tags                = local.tags\\n\\n  identity_type = \\"system\\"\\n\\n  network_profile = {\\n    plugin         = \\"azure\\"\\n    service_cidr   = \\"10.50.0.0/16\\"\\n    dns_service_ip = \\"10.50.0.10\\"\\n    outbound_type  = \\"managedNATGateway\\"\\n    network_policy = \\"azure\\"\\n  }\\n\\n  aad_admin_group_object_ids = var.aad_admin_groups\\n  enable_azure_rbac          = true\\n\\n  private_cluster_enabled           = false\\n  api_server_authorized_ip_ranges   = []\\n\\n  system_node_pool = {\\n    name      = \\"sys\\"\\n    vm_size   = \\"Standard_D4s_v5\\"\\n    min_count = 1\\n    max_count = 2\\n    node_labels = {\\n      \\"kubernetes.azure.com/mode\\" = \\"system\\"\\n    }\\n  }\\n\\n  user_node_pools = [\\n    {\\n      name      = \\"user\\"\\n      vm_size   = \\"Standard_D8s_v5\\"\\n      min_count = 2\\n      max_count = 6\\n      node_labels = {\\n        \\"kubernetes.azure.com/mode\\" = \\"user\\"\\n      }\\n    }\\n  ]\\n}\\n\\n# Beispiel: ACR + Role Assignment (au\xdferhalb des Moduls)\\nresource \\"azurerm_container_registry\\" \\"acr\\" {\\n  name                = \\"acrdevexample1234\\"\\n  resource_group_name = azurerm_resource_group.rg.name\\n  location            = var.location\\n  sku                 = \\"Standard\\"\\n  admin_enabled       = false\\n  tags                = local.tags\\n}\\n\\nresource \\"azurerm_role_assignment\\" \\"kubelet_acr_pull\\" {\\n  scope                = azurerm_container_registry.acr.id\\n  role_definition_name = \\"AcrPull\\"\\n  principal_id         = module.aks.kubelet_identity_principal_id\\n}\\n```"},{"id":"aks-node-selection","metadata":{"permalink":"/blog/aks-node-selection","source":"@site/blog/2025-01-27-aks-node-selection.md","title":"AKS Node Selection: Physische Pools vs. Virtual Nodes","description":"Strategien, um Workloads in AKS bevorzugt auf physischen User-Nodes laufen zu lassen \u2013 mit automatischem Fallback auf Virtual Nodes.","date":"2025-01-27T00:00:00.000Z","tags":[{"inline":false,"label":"Kubernetes","permalink":"/blog/tags/kubernetes","description":"Kubernetes"},{"inline":false,"label":"AKS","permalink":"/blog/tags/aks","description":"Azure Kubernetes Service"},{"inline":false,"label":"Azure","permalink":"/blog/tags/azure","description":"Azure"},{"inline":false,"label":"Nodepool","permalink":"/blog/tags/nodepool","description":"Nodepool"},{"inline":false,"label":"Virtual Node","permalink":"/blog/tags/virtual-node","description":"Virtual Node"},{"inline":false,"label":"Scheduling","permalink":"/blog/tags/scheduling","description":"Scheduling"}],"readingTime":4.42,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"aks-node-selection","title":"AKS Node Selection: Physische Pools vs. Virtual Nodes","authors":"brigitte","tags":["kubernetes","aks","azure","nodepool","virtual-node","scheduling"],"date":"2025-01-27T00:00:00.000Z","description":"Strategien, um Workloads in AKS bevorzugt auf physischen User-Nodes laufen zu lassen \u2013 mit automatischem Fallback auf Virtual Nodes."},"unlisted":false,"prevItem":{"title":"Terraform Patterns f\xfcr AKS & Azure","permalink":"/blog/terraform-patterns-aks-azure"},"nextItem":{"title":"Streaming File Uploads nach Azure Blob Storage mit Spring Boot","permalink":"/blog/springboot-fileupload-azure"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nIn vielen Projekten ist das **Kosten- und Ressourcenmodell** entscheidend:  \\n- Physische AKS-Node-Pools (`user nodes`) sind g\xfcnstiger und f\xfcr Dauer-Workloads optimiert.  \\n- **Virtual Nodes** (auf Basis von Azure Container Instances) eignen sich ideal f\xfcr **Burst-Szenarien** \u2013 wenn kurzfristig mehr Kapazit\xe4t ben\xf6tigt wird.  \\n\x3c!--truncate--\x3e\\n\ud83d\udc49 Ziel: Workloads sollen **immer zuerst** die physischen Nodes nutzen, aber automatisch auf Virtual Nodes ausweichen, wenn dort keine Ressourcen mehr frei sind.\\n\\n---\\n\\n## \u2699\ufe0f Grundlagen: Node Pools in AKS\\n- **System Pool**: interne AKS-Services  \\n- **User Pool**: physische VM-basierten Nodes (z. B. VMSS mit Standard_D4s_v5)  \\n- **Virtual Node Pool**: basiert auf ACI, hochskalierbar, Pay-per-Use, keine VM-Instanzkosten  \\n\\n---\\n\\n## \ud83d\udea7 Herausforderung\\nKubernetes verteilt Pods standardm\xe4\xdfig gleichm\xe4\xdfig \u2013 ohne \u201eBevorzugung\u201c.  \\nWenn man Virtual Nodes **nur als Notnagel** einsetzen will, braucht es eine saubere Scheduling-Strategie.\\n\\n---\\n\\n## \u2705 Strategien f\xfcr Node Selection\\n\\n### 1. NodeSelector + Taints/Tolerations\\n- User Nodes: keine speziellen Taints \u2192 Pods laufen standardm\xe4\xdfig hier.  \\n- Virtual Nodes: mit Taint versehen (`virtual-kubelet.io/provider=azure:NoSchedule`).  \\n- Nur Pods, die **tolerations** setzen, d\xfcrfen auf Virtual Nodes ausweichen.\\n\\n```yaml\\ntolerations:\\n  - key: \\"virtual-kubelet.io/provider\\"\\n    operator: \\"Equal\\"\\n    value: \\"azure\\"\\n    effect: \\"NoSchedule\\"\\n````\\n\\n\u27a1\ufe0f Vorteil: volle Kontrolle, Default = User Nodes, Virtual Nodes = Fallback.\\n\\n---\\n\\n### 2. Affinity & Preferred Scheduling\\n\\nMit `nodeAffinity` l\xe4sst sich eine **Pr\xe4ferenz** ausdr\xfccken:\\n\\n* \u201eBevorzuge User Nodes\u201c (preferred)\\n* \u201eErlaube Virtual Nodes\u201c (soft)\\n\\n```yaml\\naffinity:\\n  nodeAffinity:\\n    preferredDuringSchedulingIgnoredDuringExecution:\\n      - weight: 100\\n        preference:\\n          matchExpressions:\\n            - key: kubernetes.azure.com/mode\\n              operator: In\\n              values:\\n                - user\\n```\\n\\n\ud83d\udc49 Erst wenn dort kein Platz mehr ist, werden Pods auch auf andere Nodes (inkl. Virtual Node) verteilt.\\n\\n---\\n\\n### 3. Workload-Spezifische Steuerung\\n\\n* **Batch-/Burst-Jobs**: `tolerations` setzen, damit sie Virtual Nodes nutzen d\xfcrfen.\\n* **Dauerhafte Services**: kein Taint/Toleration \u2192 bleiben strikt auf physischen Nodes.\\n\\n---\\n\\n## \ud83d\udcca Visualisierung: Scheduling-Strategie\\n\\n```mermaid\\nflowchart TD\\n    subgraph AKS[\\"AKS Cluster\\"]\\n        subgraph UserPool[\\"User Node Pool (VMs)\\"]\\n            U1[\\"User Node 1\\"]\\n            U2[\\"User Node 2\\"]\\n            U3[\\"User Node 3\\"]\\n        end\\n\\n        subgraph VirtualPool[\\"Virtual Node Pool (ACI)\\"]\\n            V1[\\"Virtual Node\\"]\\n        end\\n\\n        P1[\\"Pod A (Deployment)\\"]\\n        P2[\\"Pod B (Job)\\"]\\n    end\\n\\n    P1 --\x3e|preferred| U1 & U2 & U3\\n    P1 -.->|fallback| V1\\n\\n    P2 --\x3e|toleration| V1\\n```\\n\\n* **Pod A (Deployment)**: bevorzugt User Nodes, f\xe4llt aber bei Ressourcenknappheit auf Virtual Nodes zur\xfcck.\\n* **Pod B (Job)**: hat explizite Toleration \u2192 darf direkt auf Virtual Nodes laufen.\\n\\n---\\n\\n## \ud83d\udccc Best Practices\\n\\n* **Monitoring**: genau tracken, wie viele Pods auf Virtual Nodes laufen (Kostenkontrolle).\\n* **SLA**: Virtual Nodes haben andere Limits (kein DaemonSet-Support, eingeschr\xe4nkte Features).\\n* **Workload-Design**: kurze Jobs und burstartige Lasten \u2192 Virtual Nodes; kritische Systeme \u2192 User Nodes.\\n* **Kostenmodell**: Physische Pools f\xfcr Grundlast, Virtual Nodes nur f\xfcr Spitzen.\\n\\n<Admonition type=\\"tip\\" title=\\"Kostenfalle vermeiden\\">\\nSetzt Limits und Autoscaling sauber, sonst landen zu viele Pods dauerhaft auf teuren Virtual Nodes!\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nMit **Affinity, Taints & Tolerations** l\xe4sst sich ein zweistufiges Scheduling umsetzen:\\n\\n* Dauerhafte Workloads laufen zuverl\xe4ssig und kosteneffizient auf physischen User Nodes.\\n* Lastspitzen landen automatisch auf Virtual Nodes \u2013 flexibel, skalierbar und ohne Overprovisioning.\\n\\n---\\n\\n## \ud83d\udce6 Beispiel\u2011Manifeste (Deployment & BatchJob)\\n\\n> Annahmen:\\n>\\n> * **User Nodes** tragen das Label: `kubernetes.azure.com/mode=user`\\n> * **Virtual Nodes** sind mit `virtual-kubelet.io/provider=azure:NoSchedule` getaintet\\n> * Cluster hat mindestens einen Linux Virtual Node (ACI)\\n\\n### 1) Deployment: bevorzugt User Nodes, Fallback auf Virtual Node\\n\\n```yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: web-frontend\\n  labels:\\n    app: web-frontend\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: web-frontend\\n  template:\\n    metadata:\\n      labels:\\n        app: web-frontend\\n    spec:\\n      # \u2776 Bevorzuge physische User-Nodes\\n      affinity:\\n        nodeAffinity:\\n          preferredDuringSchedulingIgnoredDuringExecution:\\n            - weight: 100\\n              preference:\\n                matchExpressions:\\n                  - key: kubernetes.azure.com/mode\\n                    operator: In\\n                    values: [\\"user\\"]\\n      # \u2777 Erlaube Fallback auf Virtual Nodes (Taint tolerieren)\\n      tolerations:\\n        - key: \\"virtual-kubelet.io/provider\\"\\n          operator: \\"Equal\\"\\n          value: \\"azure\\"\\n          effect: \\"NoSchedule\\"\\n      # \u2778 Optional: Verteile Pods \xfcber User-Nodes (Kosten & Resilienz)\\n      topologySpreadConstraints:\\n        - maxSkew: 1\\n          topologyKey: kubernetes.io/hostname\\n          whenUnsatisfiable: ScheduleAnyway\\n          labelSelector:\\n            matchLabels:\\n              app: web-frontend\\n      containers:\\n        - name: app\\n          image: ghcr.io/example/web:1.2.3\\n          ports:\\n            - containerPort: 8080\\n          resources:\\n            requests:\\n              cpu: \\"250m\\"\\n              memory: \\"256Mi\\"\\n            limits:\\n              cpu: \\"1\\"\\n              memory: \\"512Mi\\"\\n```\\n\\n> Ergebnis: Solange auf User-Nodes Ressourcen frei sind, werden dort alle Replikas platziert. Erst bei Knappheit d\xfcrfen Pods dank **Toleration** auch auf Virtual Nodes geplant werden.\\n\\n---\\n\\n### 2) BatchJob: bevorzugt Virtual Node, um User-Pool zu schonen\\n\\n```yaml\\napiVersion: batch/v1\\nkind: Job\\nmetadata:\\n  name: image-transcode\\nspec:\\n  completions: 5\\n  parallelism: 5\\n  backoffLimit: 0\\n  template:\\n    spec:\\n      # \u2776 Bevorzuge Virtual Node (weich), erlaube aber User als Backup\\n      affinity:\\n        nodeAffinity:\\n          preferredDuringSchedulingIgnoredDuringExecution:\\n            - weight: 100\\n              preference:\\n                matchExpressions:\\n                  - key: kubernetes.io/role\\n                    operator: In\\n                    values: [\\"virtual-node\\"]\\n      # \u2777 Toleration f\xfcr den Virtual-Node-Taint (n\xf6tig zum Scheduling)\\n      tolerations:\\n        - key: \\"virtual-kubelet.io/provider\\"\\n          operator: \\"Equal\\"\\n          value: \\"azure\\"\\n          effect: \\"NoSchedule\\"\\n      restartPolicy: Never\\n      containers:\\n        - name: worker\\n          image: ghcr.io/example/transcoder:2.0.0\\n          args: [\\"--input\\", \\"$(INPUT)\\", \\"--output\\", \\"$(OUTPUT)\\"]\\n          env:\\n            - name: INPUT\\n              value: \\"/data/in\\"\\n            - name: OUTPUT\\n              value: \\"/data/out\\"\\n          resources:\\n            requests:\\n              cpu: \\"1\\"\\n              memory: \\"1Gi\\"\\n            limits:\\n              cpu: \\"2\\"\\n              memory: \\"2Gi\\"\\n```\\n\\n> Hinweis: Der Key `kubernetes.io/role=virtual-node` ist **ein Beispiel-Label**. In vielen Clustern existiert bereits ein passendes Label auf Virtual Nodes (z.\u202fB. `type=virtual-kubelet` oder `kubernetes.azure.com/virtual-node=true`). Passe den **Match-Expression** an eure tats\xe4chlichen Node-Labels an.\\n\\n---\\n\\n### 3) Variante: Striktes Trennen per NodeSelector\\n\\nWenn bestimmte Workloads **nie** auf Virtual Nodes laufen sollen, nutze einen harten `nodeSelector` auf User-Nodes **ohne** Toleration:\\n\\n```yaml\\nspec:\\n  template:\\n    spec:\\n      nodeSelector:\\n        kubernetes.azure.com/mode: \\"user\\"\\n      # Keine Toleration \u2192 kein Scheduling auf Virtual Nodes m\xf6glich\\n```\\n\\nUnd umgekehrt (nur Virtual Node):\\n\\n```yaml\\nspec:\\n  template:\\n    spec:\\n      tolerations:\\n        - key: \\"virtual-kubelet.io/provider\\"\\n          operator: \\"Equal\\"\\n          value: \\"azure\\"\\n          effect: \\"NoSchedule\\"\\n      nodeSelector:\\n        kubernetes.azure.com/virtual-node: \\"true\\" # Beispiel-Label, bei euch anpassen\\n```\\n\\n---\\n\\n### 4) Horizontal Pod Autoscaler (HPA) als Burst-Trigger\\n\\n```yaml\\napiVersion: autoscaling/v2\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  name: web-frontend\\nspec:\\n  scaleTargetRef:\\n    apiVersion: apps/v1\\n    kind: Deployment\\n    name: web-frontend\\n  minReplicas: 3\\n  maxReplicas: 30\\n  metrics:\\n    - type: Resource\\n      resource:\\n        name: cpu\\n        target:\\n          type: Utilization\\n          averageUtilization: 70\\n```"},{"id":"springboot-fileupload-azure","metadata":{"permalink":"/blog/springboot-fileupload-azure","source":"@site/blog/2025-01-20-springboot-fileupload-azure.md","title":"Streaming File Uploads nach Azure Blob Storage mit Spring Boot","description":"Speicherschonende Verarbeitung gro\xdfer Uploads direkt in Azure Storage \u2013 ohne Zwischenspeicherung im RAM.","date":"2025-01-20T00:00:00.000Z","tags":[{"inline":false,"label":"Spring Boot","permalink":"/blog/tags/spring-boot","description":"Spring Boot"},{"inline":false,"label":"Kotlin","permalink":"/blog/tags/kotlin","description":"Kotlin"},{"inline":false,"label":"Java","permalink":"/blog/tags/java","description":"Java"},{"inline":false,"label":"Azure","permalink":"/blog/tags/azure","description":"Azure"},{"inline":false,"label":"Blob Storage","permalink":"/blog/tags/blob-storage","description":"Blob Storage"},{"inline":false,"label":"Fileupload","permalink":"/blog/tags/fileupload","description":"Fileupload"}],"readingTime":7.79,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"springboot-fileupload-azure","title":"Streaming File Uploads nach Azure Blob Storage mit Spring Boot","authors":"brigitte","tags":["spring-boot","kotlin","java","azure","blob-storage","fileupload"],"date":"2025-01-20T00:00:00.000Z","description":"Speicherschonende Verarbeitung gro\xdfer Uploads direkt in Azure Storage \u2013 ohne Zwischenspeicherung im RAM."},"unlisted":false,"prevItem":{"title":"AKS Node Selection: Physische Pools vs. Virtual Nodes","permalink":"/blog/aks-node-selection"},"nextItem":{"title":"Workload Identity in AKS \u2013 Lessons Learned","permalink":"/blog/workload-identity-lessons-learned"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nWer gro\xdfe Dateien (mehrere Gigabyte) \xfcber eine Webanwendung hochladen m\xf6chte, st\xf6\xdft schnell an Grenzen:  \\n- Klassische Multipart-Verarbeitung l\xe4dt alles in den Speicher oder auf die Platte.  \\n- Uploads dauern lange und blockieren Threads.  \\n- Fehler beim Upload f\xfchren zu inkonsistenten Datenst\xe4nden.  \\n\x3c!-- truncate --\x3e\\n\\nMit einem **streamingbasierten Ansatz** k\xf6nnen Dateien direkt beim Upload in Azure Blob Storage geschrieben werden \u2013 ohne dass sie jemals im RAM oder auf der Platte zwischengespeichert werden.\\n\\n---\\n\\n## \u2699\ufe0f Setup\\n\\n- **Spring Boot + Kotlin** als Basis  \\n- [`commons-fileupload2-core`](https://commons.apache.org/proper/commons-fileupload/) f\xfcr das Streaming-Multipart-Parsing  \\n- **Azure Blob Storage SDK** f\xfcr das Schreiben von Streams in Blobs  \\n- **SAS-Tokens** f\xfcr scoped & zeitlich begrenzten Zugriff  \\n\\n### Streaming Multipart Upload\\n\\n```kotlin\\nval iterator = FileUploadStreaming.getItemIterator(request)\\nwhile (iterator.hasNext()) {\\n    val item = iterator.next()\\n    if (!item.isFormField) {\\n        val blobClient = containerClient.getBlobClient(item.name)\\n        blobClient.getBlockBlobClient().upload(item.inputStream, item.size, true)\\n    }\\n}\\n```\\n\\n\ud83d\udc49 Keine Datei landet auf der Platte oder im Arbeitsspeicher \u2013 der InputStream wird direkt nach Azure durchgereicht.\\n\\n---\\n\\n## \ud83d\udd0d Erweiterung: MIME-Type mit Tika ermitteln\\n\\nOft reicht der vom Client mitgelieferte `Content-Type` nicht. Um den **tats\xe4chlichen MIME-Type** zu bestimmen, kann ein **Custom InputStream** genutzt werden, der die ersten Bytes cached, damit [Apache Tika](https://tika.apache.org/) eine Erkennung vornehmen kann:\\n\\n```kotlin\\nclass TikaInputStream(private val source: InputStream) : InputStream() {\\n    private val buffer = ByteArrayOutputStream()\\n    private var replay: ByteArrayInputStream? = null\\n    private var probed = false\\n\\n    override fun read(): Int {\\n        val replayStream = replay\\n        return if (replayStream != null) {\\n            replayStream.read()\\n        } else {\\n            val b = source.read()\\n            if (!probed && b != -1) buffer.write(b)\\n            b\\n        }\\n    }\\n\\n    fun detectMimeType(): String {\\n        if (!probed) {\\n            probed = true\\n            val bytes = buffer.toByteArray()\\n            replay = ByteArrayInputStream(bytes)\\n            return Tika().detect(bytes)\\n        }\\n        return \\"application/octet-stream\\"\\n    }\\n}\\n```\\n\\n\u26a1 Vorteil: MIME-Erkennung passiert **im Stream**, ohne dass die Datei vollst\xe4ndig eingelesen werden muss.\\n\\n---\\n\\n## \ud83d\udce6 On-the-Fly-Kompression\\n\\nF\xfcr bestimmte Datentypen lohnt sich **On-the-fly-Kompression**. Dabei wird der Upload-Stream direkt in einen `GZIPOutputStream` verpackt, bevor er nach Azure wandert:\\n\\n```kotlin\\nval blobClient = containerClient.getBlobClient(\\"${item.name}.gz\\")\\nblobClient.getBlockBlobClient().upload(\\n    GZIPOutputStream(item.inputStream),\\n    item.size, // ggf. unbekannt, dann -1 und chunked upload verwenden\\n    true\\n)\\n```\\n\\n* Spart massiv Speicherplatz und Bandbreite.\\n* Sollte **optional** sein (z. B. abh\xe4ngig vom MIME-Type aus Tika).\\n* Achtung bei Bin\xe4rdateien (Videos, Bilder): hier bringt Kompression meist keinen Vorteil.\\n\\n---\\n\\n## \ud83d\udea7 Stolpersteine\\n\\n* **Multipart-Parsing:** Streams m\xfcssen zuverl\xe4ssig geschlossen werden.\\n* **Content-Length:** Nicht immer vom Client geliefert \u2192 evtl. chunked Upload nutzen.\\n* **Fehlerhandling:** Bei Upload-Abbruch m\xfcssen ggf. auch Metadaten zur\xfcckgerollt werden.\\n* **Tika + Kompression:** Erkennung zuerst durchf\xfchren, danach ggf. komprimieren.\\n\\n---\\n\\n## \u2705 Best Practices\\n\\n* **Backpressure**: Uploads niemals puffern, sondern durchstreamen.\\n* **Trennung von Metadaten & Storage**: eigene Services f\xfcr Verantwortlichkeiten.\\n* **SAS-Tokens**: mit Prefix-Scopes und kurzer Laufzeit generieren.\\n* **Kombination Tika + Kompression**: Nur komprimieren, wenn es wirklich Sinn ergibt.\\n\\n<Admonition type=\\"note\\" title=\\"Praxisnutzen\\">\\nDiese Technik nutzen wir in Produktionssystemen, um Uploads im Terabyte-Bereich performant, sicher und kostenoptimiert zu verarbeiten.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nStreaming Uploads sind in Spring Boot **machbar und produktionsreif** \u2013 und durch MIME-Erkennung sowie optionale On-the-fly-Kompression sogar noch flexibler.\\nDas Resultat: **weniger Infrastrukturkosten, bessere Performance und h\xf6here Robustheit**.\\n\\n---\\n\\n> Komplettes, lauff\xe4higes Beispiel: Streaming-Multipart mit `commons-fileupload2-core`, MIME-Erkennung via Apache Tika, optionale On\u2011the\u2011fly\u2011Kompression (GZIP) und Upload direkt in Azure Blob Storage \xfcber SAS \u2013 **ohne** RAM-/Disk-Puffer.\\n\\n---\\n\\n## Projekt-Setup (Gradle Kotlin DSL)\\n\\n**`build.gradle.kts`**\\n\\n```kotlin\\nplugins {\\n    id(\\"org.springframework.boot\\") version \\"3.3.0\\"\\n    id(\\"io.spring.dependency-management\\") version \\"1.1.5\\"\\n    kotlin(\\"jvm\\") version \\"1.9.24\\"\\n    kotlin(\\"plugin.spring\\") version \\"1.9.24\\"\\n}\\n\\ngroup = \\"com.example\\"\\nversion = \\"0.0.1\\"\\njava.sourceCompatibility = JavaVersion.VERSION_17\\n\\nrepositories { mavenCentral() }\\n\\ndependencies {\\n    implementation(\\"org.springframework.boot:spring-boot-starter-web\\")\\n\\n    // Azure Blob Storage SDK v12\\n    implementation(\\"com.azure:azure-storage-blob:12.26.0\\")\\n\\n    // Streaming Multipart Parsing\\n    implementation(\\"org.apache.commons:commons-fileupload2-core:2.0.0-M1\\")\\n\\n    // Apache Tika f\xfcr MIME-Erkennung\\n    implementation(\\"org.apache.tika:tika-core:2.9.2\\")\\n\\n    // Jackson / Kotlin\\n    implementation(\\"com.fasterxml.jackson.module:jackson-module-kotlin\\")\\n    implementation(kotlin(\\"reflect\\"))\\n\\n    testImplementation(\\"org.springframework.boot:spring-boot-starter-test\\")\\n}\\n\\ntasks.test { useJUnitPlatform() }\\n```\\n\\n> **Hinweis:** Versionen ggf. auf den aktuellen Stand bringen.\\n\\n**`src/main/resources/application.yaml`**\\n\\n```yaml\\nserver:\\n  tomcat:\\n    max-swallow-size: -1 # verhindert Abbruch bei gro\xdfen Streams\\n    max-http-form-post-size: -1\\n\\nazure:\\n  storage:\\n    # Vollqualifizierte SAS-URL des Containers, z. B.:\\n    # https://<account>.blob.core.windows.net/<container>?sv=...&sig=...\\n    containerSasUrl: ${AZURE_CONTAINER_SAS_URL:}\\n\\nupload:\\n  compression:\\n    enabled: true # globaler Schalter, kann pro Request \xfcberschrieben werden\\n```\\n\\n---\\n\\n## Konfiguration: Azure Blob Container Client\\n\\n**`src/main/kotlin/com/example/upload/AzureStorageConfig.kt`**\\n\\n```kotlin\\npackage com.example.upload\\n\\nimport com.azure.storage.blob.BlobContainerClient\\nimport com.azure.storage.blob.BlobContainerClientBuilder\\nimport org.springframework.boot.context.properties.ConfigurationProperties\\nimport org.springframework.context.annotation.Bean\\nimport org.springframework.context.annotation.Configuration\\n\\n@Configuration\\nclass AzureStorageConfig {\\n    @Bean\\n    @ConfigurationProperties(prefix = \\"azure.storage\\")\\n    fun azureStorageProps() = AzureStorageProps()\\n\\n    @Bean\\n    fun blobContainerClient(props: AzureStorageProps): BlobContainerClient =\\n        BlobContainerClientBuilder()\\n            .endpoint(props.containerSasUrl)\\n            .buildClient()\\n}\\n\\nclass AzureStorageProps {\\n    /** Vollst\xe4ndige Container-SAS-URL inkl. Token */\\n    lateinit var containerSasUrl: String\\n}\\n```\\n\\n---\\n\\n## Utility: PeekableInputStream + MIME-Erkennung (Tika)\\n\\n**`src/main/kotlin/com/example/upload/io/PeekableInputStream.kt`**\\n\\n```kotlin\\npackage com.example.upload.io\\n\\nimport java.io.BufferedInputStream\\nimport java.io.InputStream\\n\\n/**\\n * Wrappt einen InputStream, erlaubt Peek via mark/reset ohne volles Einlesen.\\n */\\nclass PeekableInputStream(source: InputStream, private val peekBufferSize: Int = 8192) : InputStream() {\\n    private val inBuf = if (source.markSupported()) source else BufferedInputStream(source, peekBufferSize)\\n\\n    override fun read(): Int = inBuf.read()\\n    override fun read(b: ByteArray, off: Int, len: Int): Int = inBuf.read(b, off, len)\\n    override fun close() = inBuf.close()\\n\\n    fun <T> peek(peekLen: Int = peekBufferSize, block: (ByteArray) -> T): T {\\n        inBuf.mark(peekLen)\\n        val buf = ByteArray(peekLen)\\n        val n = inBuf.read(buf)\\n        inBuf.reset()\\n        val slice = if (n <= 0) ByteArray(0) else buf.copyOf(n)\\n        return block(slice)\\n    }\\n}\\n```\\n\\n**`src/main/kotlin/com/example/upload/mime/MimeDetector.kt`**\\n\\n```kotlin\\npackage com.example.upload.mime\\n\\nimport com.example.upload.io.PeekableInputStream\\nimport org.apache.tika.Tika\\n\\nobject MimeDetector {\\n    private val tika = Tika()\\n\\n    fun detect(peekable: PeekableInputStream, fallback: String = \\"application/octet-stream\\"): String =\\n        peekable.peek { bytes ->\\n            val detected = runCatching { tika.detect(bytes) }.getOrNull()\\n            detected ?: fallback\\n        }\\n}\\n```\\n\\n---\\n\\n## Service: Streaming Upload mit optionaler On\u2011the\u2011fly\u2011GZIP\\n\\n**`src/main/kotlin/com/example/upload/UploadService.kt`**\\n\\n```kotlin\\npackage com.example.upload\\n\\nimport com.azure.storage.blob.BlobContainerClient\\nimport com.azure.storage.blob.specialized.BlockBlobClient\\nimport com.example.upload.io.PeekableInputStream\\nimport com.example.upload.mime.MimeDetector\\nimport org.apache.commons.fileupload2.core.FileItemInputIterator\\nimport org.apache.commons.fileupload2.core.FileUpload\\nimport org.apache.commons.fileupload2.core.FileUploadException\\nimport org.apache.commons.fileupload2.core.RequestContext\\nimport org.springframework.stereotype.Service\\nimport java.io.InputStream\\nimport java.util.zip.GZIPOutputStream\\n\\n@Service\\nclass UploadService(private val container: BlobContainerClient) {\\n\\n    data class UploadResult(val files: List<FileInfo>)\\n    data class FileInfo(\\n        val fieldName: String,\\n        val filename: String,\\n        val size: Long?,\\n        val mimeType: String,\\n        val compressed: Boolean,\\n        val blobName: String\\n    )\\n\\n    /**\\n     * Streamt Multipart-Dateien direkt nach Azure. Keine Zwischenpuffer/Tempfiles.\\n     * @param request Spring/Servlet Request-Adapter f\xfcr FileUpload2\\n     * @param forceCompression optionaler Override (Header/Param)\\n     */\\n    fun handleStreamingUpload(request: RequestContext, forceCompression: Boolean? = null): UploadResult {\\n        try {\\n            val iter: FileItemInputIterator = FileUpload().getItemIterator(request)\\n            val uploaded = mutableListOf<FileInfo>()\\n\\n            while (iter.hasNext()) {\\n                val item = iter.next()\\n                if (item.isFormField) continue\\n\\n                val originalName = item.name ?: \\"upload.bin\\"\\n                val field = item.fieldName ?: \\"file\\"\\n                val size = item.headers?.getHeader(\\"Content-Length\\")?.toLongOrNull()\\n\\n                // Eingangsstream peek-f\xe4hig machen\\n                val peekable = PeekableInputStream(item.inputStream)\\n                val mime = MimeDetector.detect(peekable)\\n\\n                val shouldCompress = forceCompression\\n                    ?: shouldCompressMime(mime)\\n\\n                val (blobName, compressed) = if (shouldCompress) {\\n                    val nameGz = \\"$originalName.gz\\"\\n                    uploadStream(peekable, nameGz, compress = true)\\n                    nameGz to true\\n                } else {\\n                    uploadStream(peekable, originalName, compress = false)\\n                    originalName to false\\n                }\\n\\n                uploaded += FileInfo(\\n                    fieldName = field,\\n                    filename = originalName,\\n                    size = size,\\n                    mimeType = mime,\\n                    compressed = compressed,\\n                    blobName = blobName\\n                )\\n            }\\n\\n            return UploadResult(uploaded)\\n        } catch (e: FileUploadException) {\\n            throw RuntimeException(\\"Multipart parsing failed\\", e)\\n        }\\n    }\\n\\n    private fun shouldCompressMime(mime: String): Boolean {\\n        // Heuristik: textuell = komprimieren\\n        if (mime.startsWith(\\"text/\\")) return true\\n        return mime in setOf(\\n            \\"application/json\\",\\n            \\"application/xml\\",\\n            \\"application/x-ndjson\\",\\n            \\"text/csv\\",\\n            \\"application/csv\\"\\n        )\\n    }\\n\\n    private fun uploadStream(input: InputStream, blobName: String, compress: Boolean) {\\n        val client: BlockBlobClient = container.getBlobClient(blobName).blockBlobClient\\n\\n        // F\xfcr unbekannte L\xe4nge: \xfcber OutputStream schreiben (kein length n\xf6tig)\\n        client.getBlobOutputStream(true).use { blobOut ->\\n            if (compress) {\\n                GZIPOutputStream(blobOut).use { gz ->\\n                    input.copyTo(gz, DEFAULT_BUFFER)\\n                    // GZIPOutputStream .close() schreibt den Footer\\n                }\\n            } else {\\n                input.copyTo(blobOut, DEFAULT_BUFFER)\\n            }\\n        }\\n    }\\n\\n    companion object { const val DEFAULT_BUFFER = 1024 * 1024 }\\n}\\n```\\n\\n> Wir nutzen **`BlockBlobClient.getBlobOutputStream(overwrite = true)`**, damit keine Content-Length ben\xf6tigt wird. So bleibt der Upload vollst\xe4ndig streamingbasiert.\\n\\n---\\n\\n## Controller: Minimal-API (Servlet Request durchreichen)\\n\\n**`src/main/kotlin/com/example/upload/UploadController.kt`**\\n\\n```kotlin\\npackage com.example.upload\\n\\nimport org.apache.commons.fileupload2.core.RequestContext\\nimport org.springframework.http.MediaType\\nimport org.springframework.web.bind.annotation.PostMapping\\nimport org.springframework.web.bind.annotation.RequestHeader\\nimport org.springframework.web.bind.annotation.RequestMapping\\nimport org.springframework.web.bind.annotation.RestController\\nimport jakarta.servlet.http.HttpServletRequest\\n\\n@RestController\\n@RequestMapping(\\"/api\\")\\nclass UploadController(private val service: UploadService) {\\n\\n    @PostMapping(\\"/upload\\", consumes = [MediaType.MULTIPART_FORM_DATA_VALUE])\\n    fun upload(\\n        request: HttpServletRequest,\\n        @RequestHeader(name = \\"x-compress\\", required = false) compressHeader: String?\\n    ): UploadService.UploadResult {\\n        val forceCompression: Boolean? = compressHeader?.let { it.equals(\\"true\\", ignoreCase = true) }\\n\\n        val ctx = object : RequestContext {\\n            override fun getContentType(): String = request.contentType\\n            override fun getContentLength(): Int = request.contentLength\\n            override fun getCharacterEncoding(): String? = request.characterEncoding\\n            override fun getInputStream() = request.inputStream\\n        }\\n\\n        return service.handleStreamingUpload(ctx, forceCompression)\\n    }\\n}\\n```\\n\\n---\\n\\n## Fehlerbehandlung & (optionaler) Rollback-Beispiel\\n\\n**Pattern:** Metadaten und Blob getrennt verwalten. Erst Blob schreiben, dann Metadaten anlegen \u2013 oder umgekehrt, mit **Kompensationsaktion**.\\n\\n```kotlin\\ntry {\\n    // 1) Blob/Upload\\n    val result = service.handleStreamingUpload(ctx)\\n\\n    // 2) Metadaten an Backend senden\\n    metadataClient.createFor(result.files)\\n\\n    return result\\n} catch (ex: Exception) {\\n    // Rollback-Strategie: evtl. angelegte Metadaten l\xf6schen\\n    runCatching { metadataClient.rollback() }\\n    throw ex\\n}\\n```\\n\\n---\\n\\n## Test mit `curl`\\n\\n```bash\\ncurl -X POST \\"http://localhost:8080/api/upload\\" \\\\\\n  -H \\"x-compress: true\\" \\\\\\n  -F \\"file=@./sample.csv\\" \\\\\\n  -H \\"Expect:\\" # verhindert 100-continue Verz\xf6gerung\\n```\\n\\n---\\n\\n## Sicherheits- & Betriebsaspekte (Kurzchecklist)\\n\\n* **SAS-Token**: prefix-scoped (nur Zielpfad), kurze Laufzeit, nur ben\xf6tigte Rechte (Write/Create/Delete separat managen).\\n* **Backpressure**: keine Puffer, keine Temporary Files; Tomcat-Limits (siehe `application.yaml`).\\n* **Limits**: Server- und Proxy-Timeouts (AGIC/APIM) hoch genug einstellen.\\n* **Observability**: Upload-Dauer, Bytes, Client-IP, MIME, Kompressionsflag loggen (ohne PII). Traces f\xfcr Fehlerpfade.\\n* **Validation**: Whitelist erlaubter MIME-Types, Max-File-Size serverseitig (fr\xfchzeitig abbrechen), Virenscan je nach Bedarf.\\n\\n---\\n\\n## FAQ\\n\\n**Wie bestimme ich die Blob Content-Type/Encoding?**\\nWenn nicht komprimiert: setze `Content-Type` \xfcber Blob-HTTP-Header/Metadata. Bei GZIP: `Content-Encoding: gzip` setzen, optional Original-MIME als Benutzer-Metadatum speichern.\\n\\n**Beispiel:**\\n\\n```kotlin\\nval block = container.getBlobClient(blobName).blockBlobClient\\nval headers = com.azure.storage.blob.models.BlobHttpHeaders()\\n    .setContentType(\\"application/json\\")\\n    .setContentEncoding(\\"gzip\\")\\nblock.setHttpHeaders(headers)\\n```\\n\\n> `setHttpHeaders` kann nach dem Upload gesetzt werden (separater Call) \u2013 oder man nutzt `beginUpload`/`commitBlockList` mit Optionen.\\n\\n**Wie verhindere ich RAM-Spikes?**\\nBuffers klein halten (1\u20134 MB), `copyTo`-Buffer konstant. Keine `ByteArrayOutputStream`-Akkumulation.\\n\\n**Kann ich parallelisieren?**\\nF\xfcr reine Streaming-Endpunkte: eher nein (keine L\xe4nge). F\xfcr gro\xdfe bekannte Dateien kann `ParallelTransferOptions` beim `upload(InputStream, length)` sinnvoll sein.\\n\\n---\\n\\n## End-to-End Sequenz (vereinfachte Schritte)\\n\\n1. Client sendet Multipart \u2192 Server parsed Stream per FileUpload2.\\n2. MIME-Erkennung via Peek (Tika).\\n3. Optional GZIP \u2192 Stream wird on-the-fly komprimiert.\\n4. BlobOutputStream schreibt direkt nach Azure.\\n5. Optional: HTTP-Header/Metadata setzen, Metadaten-Service aufrufen.\\n6. Fehler \u2192 Kompensation (Rollback) ausl\xf6sen.\\n\\n---"},{"id":"workload-identity-lessons-learned","metadata":{"permalink":"/blog/workload-identity-lessons-learned","source":"@site/blog/2024-10-11-workload-identity.md","title":"Workload Identity in AKS \u2013 Lessons Learned","description":"Setup, Stolpersteine und Best Practices aus Projekten","date":"2024-11-10T00:00:00.000Z","tags":[{"inline":false,"label":"Kubernetes","permalink":"/blog/tags/kubernetes","description":"Kubernetes"},{"inline":false,"label":"Azure","permalink":"/blog/tags/azure","description":"Azure"},{"inline":false,"label":"AKS","permalink":"/blog/tags/aks","description":"Azure Kubernetes Service"},{"inline":false,"label":"Security","permalink":"/blog/tags/security","description":"Security"},{"inline":false,"label":"Identity","permalink":"/blog/tags/identity","description":"Identity"},{"inline":false,"label":"Lessons Learned","permalink":"/blog/tags/lessons-learned","description":"Lessons Learned"}],"readingTime":1.85,"hasTruncateMarker":true,"authors":[{"name":"Brigitte B\xf6hm","title":"Cloud & Data Platform Engineer","url":"https://www.linkedin.com/in/brigitte-boehm-34b7a025","page":{"permalink":"/blog/authors/brigitte"},"socials":{"github":"https://github.com/bri-b-dev","linkedin":"https://www.linkedin.com/in/brigitte-boehm-34b7a025"},"imageURL":"https://github.com/bri-b-dev.png","key":"brigitte"}],"frontMatter":{"slug":"workload-identity-lessons-learned","title":"Workload Identity in AKS \u2013 Lessons Learned","authors":"brigitte","tags":["kubernetes","azure","aks","security","identity","lessons-learned"],"date":"2024-11-10T00:00:00.000Z","description":"Setup, Stolpersteine und Best Practices aus Projekten"},"unlisted":false,"prevItem":{"title":"Streaming File Uploads nach Azure Blob Storage mit Spring Boot","permalink":"/blog/springboot-fileupload-azure"}},"content":"import Admonition from \'@theme/Admonition\';\\n\\nWorkload Identity in **Azure Kubernetes Service (AKS)** verspricht weniger Secrets, native AzureAD-Integration und eine Abl\xf6sung der alten AAD Pod Identity.  \\nIn meinen Projekten im Herbst 2024 habe ich damit aber nicht nur reibungslose Deployments, sondern auch einige Stolpersteine erlebt.  \\n\x3c!-- truncate --\x3e\\nHier meine **Erfahrungen aus der Praxis** \u2013 gegliedert nach Setup, Stolpersteinen und Best Practices.\\n\\n---\\n\\n## \u2699\ufe0f Setup\\n\\n- **Cluster**: AKS mit aktiviertem **Workload Identity Feature**  \\n- **Operator**: `azure-workload-identity` als Admission Webhook im Cluster  \\n- **Service Accounts**: Pro Pod ein SA mit Annotationen wie  \\n  ```yaml\\n  annotations:\\n    azure.workload.identity/client-id: <client-id>\\n  ```\\n\\n* **Azure-Seite**:\\n\\n  * Managed Identities f\xfcr Pods\\n  * Rollenbindung \xfcber AAD & Azure RBAC (Storage, Key Vault, Application Gateway)\\n\\n---\\n\\n## \ud83d\udea7 Stolpersteine\\n\\n### Sidecar-Injection nicht immer zuverl\xe4ssig\\n\\nDie Annotation `azure.workload.identity/inject-proxy-sidecar` funktionierte nicht in allen Operator-Versionen.\\nIn manchen F\xe4llen war ein spezielles Helm-Template oder ein zus\xe4tzliches MutatingWebhook-Setup n\xf6tig.\\n\\n### AuthorizationPermissionMismatch\\n\\nH\xe4ufiger Fehler beim Zugriff auf Storage Accounts.\\nGrund: Verwechslung von **Management Plane**-Rollen mit **Data Plane**-Rollen.\\n\u27a1\ufe0f Erst wenn die *richtigen Data Plane Roles* vergeben sind, klappt der Zugriff.\\n\\n### Helm-Templates & SecurityContext\\n\\nEin fehlerhafter `securityContext` im Helm-Chart verhinderte die Sidecar-Injektion.\\nDas Debugging kostete viel Zeit \u2013 Logs vom Webhook-Pod halfen bei der Aufkl\xe4rung.\\n\\n### Operator-Versionen mit Breaking Changes\\n\\nMinor-Releases des Operators haben das Verhalten ge\xe4ndert.\\n\u27a1\ufe0f Upgrade-Notes lesen, bevor man blind auf die neueste Version setzt.\\n\\n---\\n\\n## \u2705 Best Practices\\n\\n* **Klein anfangen**: Erst mit einem einfachen Pod + Storage Account testen.\\n* **RBAC trennen**: Management vs. Data Roles sauber unterscheiden.\\n* **Operator-Logs pr\xfcfen**: Der Admission Webhook ist die erste Anlaufstelle bei Fehlern.\\n* **Helm-Templates validieren**: Vor Deploy pr\xfcfen, ob Annotationen und Sidecars im Pod landen.\\n* **Zeit einplanen**: Realistisch f\xfcr Debugging und Iterationen kalkulieren.\\n\\n<Admonition type=\\"tip\\" title=\\"Mein Tipp\\">\\nWorkload Identity spart langfristig viel Aufwand und erh\xf6ht die Sicherheit.  \\nAber f\xfcr die Einf\xfchrung solltest du **zus\xe4tzliche Iterationen** einplanen \u2013 besonders bei komplexeren Helm-Charts.\\n</Admonition>\\n\\n---\\n\\n## \ud83d\udccc Fazit\\n\\nWorkload Identity ist ein **wichtiger Schritt f\xfcr Security und Cloud-Native-Architekturen**.\\nDie ersten Projekte waren nicht friktionsfrei, doch inzwischen laufen unsere Plattform-Komponenten stabil und ohne Secrets.\\nEin Setup, das sich definitiv lohnt \u2013 auch wenn der Weg dahin mehr Debugging erforderte, als die Doku vermuten lie\xdf.\\n\\n---\\n\\n*Wie sind deine Erfahrungen? Schreib mir gerne oder connecte dich auf [LinkedIn](https://www.linkedin.com/in/brigitte-boehm-34b7a025/).*"}]}}')}}]);